{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mUntitled-2.ipynb Cell 1\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m data\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=4'>5</a>\u001b[0m \u001b[39m#from utils import transforms\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils_dir\u001b[39;00m \u001b[39mimport\u001b[39;00m transforms\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=8'>9</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils_dir'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "#from utils import transforms\n",
    "from utils_dir import transforms\n",
    "import torchvision\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import imageio\n",
    "import random\n",
    "import collections\n",
    "import csv\n",
    "import librosa\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import librosa\n",
    "import random\n",
    "import config\n",
    "\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ContrastiveESCDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, train=True, root='./data/ESC50/ESC-50-master/audio/', config=None):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        \n",
    "        temp = os.listdir(self.root)\n",
    "        temp.sort()\n",
    "        self.file_names = []\n",
    "        if train:\n",
    "            for i in range(len(temp)):\n",
    "                if int(temp[i].split('-')[0]) in config.train_folds:\n",
    "                    self.file_names.append(temp[i])\n",
    "        else:\n",
    "            for i in range(len(temp)):\n",
    "                if int(temp[i].split('-')[0]) in config.test_fold:\n",
    "                    self.file_names.append(temp[i])\n",
    "        \n",
    "        self.mel_transform = T.MelSpectrogram(sample_rate=44100, n_mels=128, n_fft=1024, hop_length=512)\n",
    "        \n",
    "        if self.train:\n",
    "            self.wave_transforms = transforms.Compose([transforms.ToTensor1D(), \n",
    "                                                       transforms.RandomScale(max_scale = 1.25), \n",
    "                                                       transforms.RandomPadding(out_len = 220500),\n",
    "                                                       transforms.RandomCrop(out_len = 220500)])\n",
    "            \n",
    "            self.spec_transforms = transforms.Compose([transforms.ToTensor(), \n",
    "                                                       transforms.FrequencyMask(max_width=config.freq_masks_width, numbers=config.freq_masks), \n",
    "                                                       transforms.TimeMask(max_width=config.time_masks_width, numbers=config.time_masks)])\n",
    "        else:\n",
    "            self.wave_transforms = transforms.Compose([transforms.ToTensor1D(),\n",
    "                                                       transforms.RandomPadding(out_len = 220500),\n",
    "                                                       transforms.RandomCrop(out_len = 220500)])\n",
    "            \n",
    "            self.spec_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        file_name = self.file_names[index]\n",
    "        \n",
    "        # Create a positive pair and a negative sample\n",
    "        aug_wave1, aug_wave2, neg_wave = self.load_and_augment(file_name, index)\n",
    "        \n",
    "        # Create spectrograms\n",
    "        spec1 = self.generate_spectrogram(aug_wave1)\n",
    "        spec2 = self.generate_spectrogram(aug_wave2)\n",
    "        neg_spec = self.generate_spectrogram(neg_wave)\n",
    "        \n",
    "        return (spec1, spec2, neg_spec)\n",
    "\n",
    "    def load_and_augment(self, file_name, index):\n",
    "        path = os.path.join(self.root, file_name)\n",
    "        wave, _ = torchaudio.load(path, num_frames=44100)\n",
    "        wave = wave.squeeze(0)\n",
    "\n",
    "        aug_wave1 = self.process_wave(wave)\n",
    "        aug_wave2 = self.process_wave(wave)\n",
    "        \n",
    "        # Fetch a negative sample\n",
    "        neg_index = random.choice([x for x in range(len(self.file_names)) if x != index])\n",
    "        neg_file_name = self.file_names[neg_index]\n",
    "        neg_path = os.path.join(self.root, neg_file_name)\n",
    "        neg_wave, _ = torchaudio.load(neg_path, num_frames=44100)\n",
    "        neg_wave = neg_wave.squeeze(0)\n",
    "        neg_wave = self.process_wave(neg_wave)\n",
    "\n",
    "        return aug_wave1, aug_wave2, neg_wave\n",
    "\n",
    "    def process_wave(self, wave):\n",
    "        # Normalize, remove silent sections, and apply wave transforms\n",
    "        if wave.ndim == 1:\n",
    "            wave = wave[:, np.newaxis]\n",
    "\n",
    "        if np.abs(wave.max()) > 1.0:\n",
    "            wave = transforms.scale(wave, wave.min(), wave.max(), -1.0, 1.0)\n",
    "        wave = wave.T * 32768.0\n",
    "        \n",
    "        start = wave.nonzero()[1].min()\n",
    "        end = wave.nonzero()[1].max()\n",
    "        wave = wave[:, start:end+1]\n",
    "\n",
    "        wave_copy = np.copy(wave)\n",
    "        wave_copy = self.wave_transforms(wave_copy)\n",
    "        wave_copy.squeeze_(0)\n",
    "\n",
    "        return wave_copy\n",
    "\n",
    "    def generate_spectrogram(self, wave):\n",
    "        # Generating mel-spectrogram and apply spec transforms\n",
    "        s = self.mel_transform(wave)\n",
    "        log_s = torchaudio.transforms.AmplitudeToDB()(s)\n",
    "        log_s = self.spec_transforms(log_s)\n",
    "        \n",
    "        spec = torch.cat((log_s, log_s, log_s), dim=0)\n",
    "        return spec\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "from torch.utils import data\n",
    "import random\n",
    "\n",
    "def create_generators():\n",
    "    train_dataset = ContrastiveESCDataset(train=True)\n",
    "    test_dataset = ContrastiveESCDataset(train=False)\n",
    "    \n",
    "    train_loader = data.DataLoader(train_dataset, \n",
    "                                   batch_size=config.batch_size, \n",
    "                                   shuffle=True, \n",
    "                                   num_workers=10, \n",
    "                                   drop_last=False, \n",
    "                                   collate_fn=contrastive_collate_fn)\n",
    "    \n",
    "    test_loader = data.DataLoader(test_dataset, \n",
    "                                  batch_size=config.batch_size, \n",
    "                                  shuffle=True, \n",
    "                                  num_workers=10, \n",
    "                                  drop_last=False, \n",
    "                                  collate_fn=contrastive_collate_fn)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Expects a batch of (file_name, spec, class_id) tuples.\n",
    "    This will convert these tuples to batches of anchor, positive, and negative samples.\n",
    "    \"\"\"\n",
    "    anchors, positives, negatives = [], [], []\n",
    "    \n",
    "    for item in batch:\n",
    "        file_name, spec, class_id = item\n",
    "        anchors.append(spec)\n",
    "        \n",
    "        # For the sake of simplicity, let's just duplicate the anchor as the positive sample\n",
    "        # In a real-world scenario, you might want to pick another example of the same class or apply a different transformation\n",
    "        positives.append(spec)\n",
    "        \n",
    "        # Pick a random negative sample from the batch that doesn't belong to the current class_id\n",
    "        negative_class_id = class_id\n",
    "        while negative_class_id == class_id:\n",
    "            negative_item = random.choice(batch)\n",
    "            _, negative_spec, negative_class_id = negative_item\n",
    "        \n",
    "        negatives.append(negative_spec)\n",
    "    \n",
    "    return {\n",
    "        \"anchors\": torch.stack(anchors),\n",
    "        \"positives\": torch.stack(positives),\n",
    "        \"negatives\": torch.stack(negatives)\n",
    "    }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
