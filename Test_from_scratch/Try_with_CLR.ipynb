{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "#from utils import transforms\n",
    "from utils_dir import transforms \n",
    "import torchvision\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import imageio\n",
    "import random\n",
    "import collections\n",
    "import csv\n",
    "import librosa\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import random\n",
    "import config\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ContrastiveESCDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, train=True, root='./data/ESC50/ESC-50-master/audio/'):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        \n",
    "        temp = os.listdir(self.root)\n",
    "        temp.sort()\n",
    "        self.file_names = []\n",
    "        if train:\n",
    "            for i in range(len(temp)):\n",
    "                if int(temp[i].split('-')[0]) in config.train_folds:\n",
    "                    self.file_names.append(temp[i])\n",
    "        else:\n",
    "            for i in range(len(temp)):\n",
    "                if int(temp[i].split('-')[0]) in config.test_fold:\n",
    "                    self.file_names.append(temp[i])\n",
    "        \n",
    "        self.mel_transform = T.MelSpectrogram(sample_rate=44100, n_mels=32, n_fft=1024, hop_length=512)\n",
    "        \n",
    "        if self.train:\n",
    "            self.wave_transforms = torchvision.transforms.Compose([\n",
    "                transforms.ToTensor1D(), \n",
    "                transforms.RandomScale(max_scale = 1.25), \n",
    "                transforms.RandomPadding(out_len = 220500),\n",
    "                transforms.RandomCrop(out_len = 220500)\n",
    "            ])\n",
    "            self.spec_transforms = torchvision.transforms.Compose([\n",
    "                transforms.FrequencyMask(max_width=config.freq_masks_width, numbers=config.freq_masks), \n",
    "                transforms.TimeMask(max_width=config.time_masks_width, numbers=config.time_masks)\n",
    "            ])\n",
    "        else:\n",
    "            self.wave_transforms = torchvision.transforms.Compose([\n",
    "                transforms.ToTensor1D(),\n",
    "                transforms.RandomPadding(out_len = 220500),\n",
    "                transforms.RandomCrop(out_len = 220500)\n",
    "            ])\n",
    "            # Only the ToTensor transform is removed here.\n",
    "            self.spec_transforms = torchvision.transforms.Compose([])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        file_name = self.file_names[index]\n",
    "        \n",
    "        # Create a positive pair and a negative sample\n",
    "        aug_wave1, aug_wave2, neg_wave = self.load_and_augment(file_name, index)\n",
    "        \n",
    "        # Create spectrograms\n",
    "        spec1 = self.generate_spectrogram(aug_wave1)\n",
    "        spec2 = self.generate_spectrogram(aug_wave2)\n",
    "        neg_spec = self.generate_spectrogram(neg_wave)\n",
    "        \n",
    "        return (spec1, spec2, neg_spec)\n",
    "\n",
    "    def load_and_augment(self, file_name, index):\n",
    "        path = os.path.join(self.root, file_name)\n",
    "        wave, _ = torchaudio.load(path, num_frames=44100)\n",
    "        wave = wave.squeeze(0)\n",
    "\n",
    "        # Augment aug_wave2 and neg_wave\n",
    "        aug_wave2 = self.process_wave(wave)\n",
    "        neg_index = random.choice([x for x in range(len(self.file_names)) if x != index])\n",
    "        neg_file_name = self.file_names[neg_index]\n",
    "        neg_path = os.path.join(self.root, neg_file_name)\n",
    "        neg_wave, _ = torchaudio.load(neg_path, num_frames=44100)\n",
    "        neg_wave = neg_wave.squeeze(0)\n",
    "        neg_wave = self.process_wave(neg_wave)\n",
    "\n",
    "        return wave, aug_wave2, neg_wave\n",
    "\n",
    "    def process_wave(self, wave):\n",
    "        if wave.numel() == 0:\n",
    "            # Handle empty tensor (e.g., by returning a zero tensor)\n",
    "            return torch.zeros(1, self.out_len)  # Adjust the shape as needed\n",
    "\n",
    "        # Normalize, remove silent sections, and apply wave transforms\n",
    "        if wave.ndim == 1:\n",
    "            wave = wave.unsqueeze(1)\n",
    "\n",
    "        if np.abs(wave.max()) > 1.0:\n",
    "            wave = transforms.scale(wave, wave.min(), wave.max(), -1.0, 1.0)\n",
    "        \n",
    "        non_zero_indices = wave.nonzero()\n",
    "        \n",
    "        if non_zero_indices.numel() == 0:\n",
    "            # Handle the case where there are no non-zero elements in the waveform\n",
    "            return torch.zeros(1, self.out_len)  # Adjust the shape as needed\n",
    "        \n",
    "        start = non_zero_indices[:, 1].min()\n",
    "        end = non_zero_indices[:, 1].max()\n",
    "        \n",
    "        wave = wave[:, start:end+1]\n",
    "\n",
    "        wave_copy = np.copy(wave)\n",
    "        wave_copy = self.wave_transforms(wave_copy)\n",
    "        wave_copy.squeeze_(0)\n",
    "\n",
    "        return wave_copy\n",
    "\n",
    "\n",
    "    def generate_spectrogram(self, wave):\n",
    "        # Generating mel-spectrogram and apply spec transforms\n",
    "        s = self.mel_transform(wave)\n",
    "        log_s = torchaudio.transforms.AmplitudeToDB()(s)\n",
    "        \n",
    "        # Add batch dimension if it's not already there\n",
    "        if log_s.ndim == 2:\n",
    "            log_s = log_s.unsqueeze(0)\n",
    "        \n",
    "        log_s = self.spec_transforms(log_s)\n",
    "        \n",
    "        spec = torch.cat((log_s, log_s, log_s), dim=0)\n",
    "        return spec\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_generators():\n",
    "    train_dataset = ContrastiveESCDataset(train=True)\n",
    "    test_dataset = ContrastiveESCDataset(train=False)\n",
    "    \n",
    "    train_loader = data.DataLoader(train_dataset, \n",
    "                                   batch_size=4, \n",
    "                                   shuffle=True, \n",
    "                                   num_workers=0, \n",
    "                                   drop_last=True, \n",
    "                                   collate_fn=contrastive_collate_fn)\n",
    "    \n",
    "    test_loader = data.DataLoader(test_dataset, \n",
    "                                  batch_size=4, \n",
    "                                  shuffle=False, \n",
    "                                  num_workers=0, \n",
    "                                  drop_last=True, \n",
    "                                  collate_fn=contrastive_collate_fn)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_collate_fn(batch):\n",
    "    anchors, positives, negatives = [], [], []\n",
    "\n",
    "    for item in batch:\n",
    "        spec1, spec2, neg_spec = item\n",
    "        anchors.append(spec1)\n",
    "        positives.append(spec2)\n",
    "        negatives.append(neg_spec)\n",
    "\n",
    "    return {\n",
    "        \"anchors\": torch.stack(anchors),\n",
    "        \"positives\": torch.stack(positives),\n",
    "        \"negatives\": torch.stack(negatives)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 64 * 216, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the contrastive loss\n",
    "def contrastive_loss(anchor, positive, negative, margin=0.5):\n",
    "    pos_distance = F.pairwise_distance(anchor, positive)\n",
    "    neg_distance = F.pairwise_distance(anchor, negative)\n",
    "    loss = torch.mean(torch.clamp(pos_distance - neg_distance + margin, min=0.0))\n",
    "    return loss\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SmallCNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_loader, test_loader = create_generators()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 38896200000 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Gabriel\\OneDrive\\Dokumente\\GitHub\\MA-pre-work\\Test_from_scratch\\Try_with_CLR.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Try_with_CLR.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m accumulation_steps \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m  \u001b[39m# Accumulate gradients over 4 small batches before updating\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Try_with_CLR.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Try_with_CLR.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Try_with_CLR.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mI dua wos !!!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Try_with_CLR.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     anchors, positives, negatives \u001b[39m=\u001b[39m batch\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32mc:\\Users\\Gabriel\\OneDrive\\Dokumente\\GitHub\\MA-pre-work\\Test_from_scratch\\Try_with_CLR.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Try_with_CLR.ipynb#X10sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m file_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_names[index]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Try_with_CLR.ipynb#X10sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39m# Create a positive pair and a negative sample\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Try_with_CLR.ipynb#X10sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m aug_wave1, aug_wave2, neg_wave \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_and_augment(file_name, index)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Try_with_CLR.ipynb#X10sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39m# Create spectrograms\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Try_with_CLR.ipynb#X10sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m spec1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate_spectrogram(aug_wave1)\n",
      "\u001b[1;32mc:\\Users\\Gabriel\\OneDrive\\Dokumente\\GitHub\\MA-pre-work\\Test_from_scratch\\Try_with_CLR.ipynb Cell 9\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Try_with_CLR.ipynb#X10sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m wave \u001b[39m=\u001b[39m wave\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Try_with_CLR.ipynb#X10sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39m# Augment aug_wave2 and neg_wave\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Try_with_CLR.ipynb#X10sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m aug_wave2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess_wave(wave)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Try_with_CLR.ipynb#X10sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m neg_index \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mchoice([x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_names)) \u001b[39mif\u001b[39;00m x \u001b[39m!=\u001b[39m index])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Try_with_CLR.ipynb#X10sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m neg_file_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_names[neg_index]\n",
      "\u001b[1;32mc:\\Users\\Gabriel\\OneDrive\\Dokumente\\GitHub\\MA-pre-work\\Test_from_scratch\\Try_with_CLR.ipynb Cell 9\u001b[0m line \u001b[0;36m9\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Try_with_CLR.ipynb#X10sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m wave \u001b[39m=\u001b[39m wave[:, start:end\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Try_with_CLR.ipynb#X10sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m wave_copy \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcopy(wave)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Try_with_CLR.ipynb#X10sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m wave_copy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwave_transforms(wave_copy)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Try_with_CLR.ipynb#X10sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m wave_copy\u001b[39m.\u001b[39msqueeze_(\u001b[39m0\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Try_with_CLR.ipynb#X10sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m \u001b[39mreturn\u001b[39;00m wave_copy\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\OneDrive\\Dokumente\\GitHub\\MA-pre-work\\Test_from_scratch\\utils_dir\\transforms.py:137\u001b[0m, in \u001b[0;36mRandomPadding.__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_pad(x) \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_len \u001b[39melse\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\OneDrive\\Dokumente\\GitHub\\MA-pre-work\\Test_from_scratch\\utils_dir\\transforms.py:128\u001b[0m, in \u001b[0;36mRandomPadding.random_pad\u001b[1;34m(self, signal)\u001b[0m\n\u001b[0;32m    126\u001b[0m pad_value_left \u001b[39m=\u001b[39m signal[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mto(signal\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m    127\u001b[0m pad_value_right \u001b[39m=\u001b[39m signal[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mto(signal\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m--> 128\u001b[0m output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat((\n\u001b[0;32m    129\u001b[0m     torch\u001b[39m.\u001b[39;49mzeros(signal\u001b[39m.\u001b[39;49mshape[:\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m] \u001b[39m+\u001b[39;49m (left,), dtype\u001b[39m=\u001b[39;49msignal\u001b[39m.\u001b[39;49mdtype, device\u001b[39m=\u001b[39;49msignal\u001b[39m.\u001b[39;49mdevice)\u001b[39m.\u001b[39;49mfill_(pad_value_left),\n\u001b[0;32m    130\u001b[0m     signal,\n\u001b[0;32m    131\u001b[0m     torch\u001b[39m.\u001b[39;49mzeros(signal\u001b[39m.\u001b[39;49mshape[:\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m] \u001b[39m+\u001b[39;49m (right,), dtype\u001b[39m=\u001b[39;49msignal\u001b[39m.\u001b[39;49mdtype, device\u001b[39m=\u001b[39;49msignal\u001b[39m.\u001b[39;49mdevice)\u001b[39m.\u001b[39;49mfill_(pad_value_right)\n\u001b[0;32m    132\u001b[0m ), dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    134\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 38896200000 bytes."
     ]
    }
   ],
   "source": [
    "accumulation_steps = 4  # Accumulate gradients over 4 small batches before updating\n",
    "optimizer.zero_grad()\n",
    "\n",
    "for i, batch in enumerate(train_loader):\n",
    "    print(\"I dua wos !!!\")\n",
    "    anchors, positives, negatives = batch\n",
    "    anchors = anchors.to(device)\n",
    "    positives = positives.to(device)\n",
    "    negatives = negatives.to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    anchor_out = model(anchors)\n",
    "    positive_out = model(positives)\n",
    "    negative_out = model(negatives)\n",
    "    \n",
    "    loss = contrastive_loss(anchor_out, positive_out, negative_out)\n",
    "    loss = loss / accumulation_steps  # Divide the loss by the accumulation steps\n",
    "    \n",
    "    loss.backward()\n",
    "    print(\"I dua wos !!!\")\n",
    "    if (i + 1) % accumulation_steps == 0:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "# Make sure to update the model one more time if there are remaining accumulated gradients.\n",
    "if i % accumulation_steps != 0:\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ContrastiveESCDataset(train=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "\n",
    "def plot_spec(spec1, spec2, neg_spec):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Plot the first spectrogram\n",
    "    plt.subplot(131)\n",
    "    librosa.display.specshow(spec1.numpy(), cmap='viridis', y_axis='mel')\n",
    "    plt.title('Spectrogram 1')\n",
    "    \n",
    "    # Plot the second spectrogram\n",
    "    plt.subplot(132)\n",
    "    librosa.display.specshow(spec2.numpy(), cmap='viridis', y_axis='mel')\n",
    "    plt.title('Spectrogram 2')\n",
    "    \n",
    "    # Plot the negative spectrogram\n",
    "    plt.subplot(133)\n",
    "    librosa.display.specshow(neg_spec.numpy(), cmap='viridis', y_axis='mel')\n",
    "    plt.title('Negative Spectrogram')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming you have already created the train_dataset\n",
    "spec1, spec2, neg_spec = train_dataset[0]\n",
    "plot_spec(spec1, spec2, neg_spec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
