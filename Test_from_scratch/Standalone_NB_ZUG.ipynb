{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import torch\n",
    "import torchaudio.transforms as T\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#import own modules\n",
    "import config\n",
    "from utils_dir import transforms \n",
    "\n",
    "#empty cache\n",
    "torch.cuda.empty_cache()\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "###############Dataloader for training the model####################\n",
    "from DL_finetune import ESC_50_DL_finetune_ZUG as DSf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet50_Classifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Resnet50_Classifier, self).__init__()\n",
    "\n",
    "        # Load the pretrained ResNet-50 model\n",
    "        self.resnet50 = models.resnet50(pretrained=True)\n",
    "\n",
    "        # Change the first layer to accept 1-channel input (instead of the default 3 channels for RGB)\n",
    "        self.resnet50.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        \n",
    "        # Modify the last fully connected layer to match the number of classes\n",
    "        num_features = self.resnet50.fc.in_features\n",
    "        self.resnet50.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet50(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 400\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-5  # L2 regularization\n",
    "batch_size = 32\n",
    "\n",
    "# Device configuration\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 60  # This value can be changed based on how many epochs of no improvement you're willing to wait\n",
    "early_stop_counter = 0\n",
    "\n",
    "# Initialize dataset and dataloaders\n",
    "train_loader, test_loader = DSf.create_generators_finetune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 66/66 [31:20<00:00, 28.50s/it]\n",
      "100%|██████████| 9/9 [03:01<00:00, 20.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss improved! Saving the model...\n",
      "Epoch [1/400], Train Loss: 0.9848, Val Loss: 0.7666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [24:46<00:00, 22.53s/it]\n",
      "100%|██████████| 9/9 [02:51<00:00, 19.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/400], Train Loss: 0.7841, Val Loss: 0.8396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [24:23<00:00, 22.17s/it]\n",
      "100%|██████████| 9/9 [02:52<00:00, 19.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/400], Train Loss: 0.7588, Val Loss: 0.8695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [24:28<00:00, 22.25s/it]\n",
      "100%|██████████| 9/9 [02:58<00:00, 19.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/400], Train Loss: 0.7223, Val Loss: 1.0786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [24:42<00:00, 22.45s/it]\n",
      "100%|██████████| 9/9 [02:51<00:00, 19.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/400], Train Loss: 0.7389, Val Loss: 1.0291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [25:01<00:00, 22.75s/it]\n",
      "100%|██████████| 9/9 [02:52<00:00, 19.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/400], Train Loss: 0.7319, Val Loss: 0.8552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [25:16<00:00, 22.97s/it]\n",
      "100%|██████████| 9/9 [02:51<00:00, 19.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/400], Train Loss: 0.7227, Val Loss: 1.1486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [24:17<00:00, 22.08s/it]\n",
      "100%|██████████| 9/9 [02:52<00:00, 19.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss improved! Saving the model...\n",
      "Epoch [8/400], Train Loss: 0.7047, Val Loss: 0.6623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [24:29<00:00, 22.26s/it]\n",
      "100%|██████████| 9/9 [02:48<00:00, 18.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss improved! Saving the model...\n",
      "Epoch [9/400], Train Loss: 0.7031, Val Loss: 0.6595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [24:39<00:00, 22.42s/it]\n",
      "100%|██████████| 9/9 [02:49<00:00, 18.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/400], Train Loss: 0.6752, Val Loss: 0.9930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [24:20<00:00, 22.13s/it]\n",
      "100%|██████████| 9/9 [02:48<00:00, 18.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/400], Train Loss: 0.6530, Val Loss: 0.7314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [24:10<00:00, 21.98s/it]\n",
      "100%|██████████| 9/9 [02:46<00:00, 18.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/400], Train Loss: 0.6815, Val Loss: 0.9089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [24:35<00:00, 22.36s/it]\n",
      "100%|██████████| 9/9 [02:51<00:00, 19.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/400], Train Loss: 0.6662, Val Loss: 0.7036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [25:49<00:00, 23.48s/it]\n",
      "100%|██████████| 9/9 [02:50<00:00, 18.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/400], Train Loss: 0.6694, Val Loss: 1.6173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [25:59<00:00, 23.63s/it]\n",
      "100%|██████████| 9/9 [02:48<00:00, 18.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/400], Train Loss: 0.6431, Val Loss: 1.2688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [25:52<00:00, 23.52s/it]\n",
      "100%|██████████| 9/9 [02:48<00:00, 18.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/400], Train Loss: 0.6796, Val Loss: 1.4416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [25:43<00:00, 23.39s/it]\n",
      "100%|██████████| 9/9 [02:46<00:00, 18.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/400], Train Loss: 0.6548, Val Loss: 0.7566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [25:41<00:00, 23.36s/it]\n",
      "100%|██████████| 9/9 [02:47<00:00, 18.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss improved! Saving the model...\n",
      "Epoch [18/400], Train Loss: 0.6522, Val Loss: 0.6300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [25:53<00:00, 23.54s/it]\n",
      "100%|██████████| 9/9 [02:48<00:00, 18.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/400], Train Loss: 0.6659, Val Loss: 0.6500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [25:46<00:00, 23.43s/it]\n",
      "100%|██████████| 9/9 [02:47<00:00, 18.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/400], Train Loss: 0.6260, Val Loss: 1.0574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [25:35<00:00, 23.27s/it]\n",
      "100%|██████████| 9/9 [02:45<00:00, 18.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/400], Train Loss: 0.6389, Val Loss: 0.6656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [25:45<00:00, 23.42s/it]\n",
      "100%|██████████| 9/9 [02:46<00:00, 18.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/400], Train Loss: 0.6387, Val Loss: 1.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [25:21<00:00, 23.05s/it]\n",
      "100%|██████████| 9/9 [02:49<00:00, 18.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/400], Train Loss: 0.6263, Val Loss: 1.0384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [25:07<00:00, 22.84s/it]\n",
      "100%|██████████| 9/9 [02:45<00:00, 18.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss improved! Saving the model...\n",
      "Epoch [24/400], Train Loss: 0.6281, Val Loss: 0.5727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [25:09<00:00, 22.87s/it]\n",
      "100%|██████████| 9/9 [02:49<00:00, 18.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/400], Train Loss: 0.6201, Val Loss: 0.6905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [25:15<00:00, 22.96s/it]\n",
      "100%|██████████| 9/9 [02:48<00:00, 18.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/400], Train Loss: 0.6152, Val Loss: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [25:41<00:00, 23.36s/it]\n",
      "100%|██████████| 9/9 [02:48<00:00, 18.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/400], Train Loss: 0.5963, Val Loss: 1.9008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [25:43<00:00, 23.39s/it]\n",
      "100%|██████████| 9/9 [02:49<00:00, 18.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/400], Train Loss: 0.6031, Val Loss: 1.4962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [26:07<00:00, 23.75s/it]\n",
      "100%|██████████| 9/9 [02:50<00:00, 18.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/400], Train Loss: 0.5907, Val Loss: 0.7828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [25:41<00:00, 23.36s/it]\n",
      "100%|██████████| 9/9 [02:48<00:00, 18.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/400], Train Loss: 0.6174, Val Loss: 0.7355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [25:42<00:00, 23.38s/it]\n",
      "100%|██████████| 9/9 [02:47<00:00, 18.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/400], Train Loss: 0.6180, Val Loss: 0.9092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [25:47<00:00, 23.45s/it]\n",
      "100%|██████████| 9/9 [02:47<00:00, 18.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/400], Train Loss: 0.6254, Val Loss: 0.8222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [25:33<00:00, 23.24s/it]\n",
      "100%|██████████| 9/9 [02:47<00:00, 18.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/400], Train Loss: 0.6103, Val Loss: 0.9534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [25:46<00:00, 23.43s/it]\n",
      "100%|██████████| 9/9 [02:52<00:00, 19.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/400], Train Loss: 0.6147, Val Loss: 0.7854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [25:28<00:00, 23.16s/it]\n",
      "100%|██████████| 9/9 [02:51<00:00, 19.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/400], Train Loss: 0.5940, Val Loss: 0.9201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [25:40<00:00, 23.34s/it]\n",
      "100%|██████████| 9/9 [02:47<00:00, 18.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/400], Train Loss: 0.6260, Val Loss: 0.6058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [25:48<00:00, 23.46s/it]\n",
      "100%|██████████| 9/9 [02:50<00:00, 18.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/400], Train Loss: 0.6015, Val Loss: 0.8088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [25:55<00:00, 23.56s/it]\n",
      "100%|██████████| 9/9 [02:49<00:00, 18.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/400], Train Loss: 0.5940, Val Loss: 1.3228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [25:54<00:00, 23.55s/it]\n",
      "100%|██████████| 9/9 [02:47<00:00, 18.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/400], Train Loss: 0.5991, Val Loss: 0.6138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [26:13<00:00, 23.83s/it]\n",
      "100%|██████████| 9/9 [02:50<00:00, 18.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/400], Train Loss: 0.5894, Val Loss: 1.1322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [25:59<00:00, 23.62s/it]\n",
      "100%|██████████| 9/9 [02:47<00:00, 18.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/400], Train Loss: 0.5921, Val Loss: 0.6216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [26:03<00:00, 23.69s/it]\n",
      "100%|██████████| 9/9 [02:48<00:00, 18.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/400], Train Loss: 0.5770, Val Loss: 0.7089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [26:08<00:00, 23.76s/it]\n",
      "100%|██████████| 9/9 [02:50<00:00, 18.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/400], Train Loss: 0.5959, Val Loss: 0.8885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [25:57<00:00, 23.60s/it]\n",
      "100%|██████████| 9/9 [02:48<00:00, 18.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/400], Train Loss: 0.5985, Val Loss: 0.8087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 19/66 [08:06<20:03, 25.62s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Gabriel\\OneDrive\\Dokumente\\GitHub\\MA-pre-work\\Test_from_scratch\\Standalone_NB_ZUG.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Standalone_NB_ZUG.ipynb#W3sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Standalone_NB_ZUG.ipynb#W3sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Standalone_NB_ZUG.ipynb#W3sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Standalone_NB_ZUG.ipynb#W3sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m avg_train_loss \u001b[39m=\u001b[39m train_loss \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(train_loader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Standalone_NB_ZUG.ipynb#W3sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m# Validation loop\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 400\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-5  # L2 regularization\n",
    "batch_size = 32\n",
    "\n",
    "# Device configuration\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 60  # This value can be changed based on how many epochs of no improvement you're willing to wait\n",
    "early_stop_counter = 0\n",
    "\n",
    "# Initialize dataset and dataloaders\n",
    "train_loader, test_loader = DSf.create_generators_finetune()\n",
    "\n",
    "# Initialize the Classifier\n",
    "num_classes = 50  \n",
    "model = Resnet50_Classifier(num_classes=num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Create log directory\n",
    "current_date = datetime.datetime.now().strftime('%Y-%m-%d-%H')\n",
    "log_dir = f\"./results_standalone/ResnetClassifier-{current_date}-epochs-{num_epochs}\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Log file path\n",
    "log_file_path = os.path.join(log_dir, \"training_log.txt\")\n",
    "\n",
    "# Variables for checkpointing\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for _, (file_name, data, labels) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for _, (file_name, data, labels) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "\n",
    "    # Check for early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        print(\"Validation Loss improved! Saving the model...\")\n",
    "        torch.save(model, log_dir + '/checkpoint.pth')\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "    \n",
    "    # Log to file\n",
    "    with open(log_file_path, 'a') as log_file:\n",
    "        log_file.write(f\"Epoch [{epoch+1}/{num_epochs}] Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [03:09<00:00, 21.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results:\n",
      "Accuracy: 74.18%\n",
      "Precision: 74.53%\n",
      "Recall: 74.18%\n",
      "F1-score: 73.09%\n",
      "Confusion Matrix:\n",
      "[[220   7  40   0]\n",
      " [ 37  37   3   0]\n",
      " [ 41   0 146   0]\n",
      " [  1  11   1   2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "# Initialize dataset and dataloaders\n",
    "train_loader, test_loader = DSf.create_generators_finetune()\n",
    "\n",
    "model = torch.load('results_standalone/ResnetClassifier-2023-10-02-17-epochs-400/checkpoint.pth')\n",
    "\n",
    "\n",
    "def evaluate_model_standalone(test_loader, model):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (file_name, data, labels) in tqdm(test_loader):\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(data)\n",
    "            \n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            pred_labels.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "            \n",
    "    # Calculate accuracy\n",
    "    correct_preds = sum(t == p for t, p in zip(true_labels, pred_labels))\n",
    "    accuracy = correct_preds / len(true_labels)\n",
    "\n",
    "    # Calculate precision, recall, F1-score\n",
    "    precision, recall, f1_score, support = precision_recall_fscore_support(true_labels, pred_labels, average='weighted')\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    conf_mat = confusion_matrix(true_labels, pred_labels)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"\\nEvaluation Results:\")\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall * 100:.2f}%\")\n",
    "    print(f\"F1-score: {f1_score * 100:.2f}%\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_mat)\n",
    "\n",
    "# Call the evaluate function after training\n",
    "evaluate_model_standalone(test_loader, model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
