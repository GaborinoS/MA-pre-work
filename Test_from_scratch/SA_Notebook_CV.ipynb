{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio.transforms as T\n",
    "import torchvision.models as models\n",
    "import torchaudio\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "# Implement Stratified K-Folds Cross-validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.ADSMI:\n",
    "    from DL_finetune import ADSMI_DL_CV as DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(config.channels)\n",
    "\n",
    "class Resnet50_Classifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Resnet50_Classifier, self).__init__()\n",
    "        self.resnet50 = models.resnet50(pretrained=True)\n",
    "        self.resnet50.conv1 = nn.Conv2d(config.channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        num_features = self.resnet50.fc.in_features\n",
    "        self.resnet50.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet50(x)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class ResNet101_Classifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNet101_Classifier, self).__init__()\n",
    "        self.resnet101 = models.resnet101(pretrained=True)\n",
    "        # Modify the input layer to match your input data channels\n",
    "        # If your input data has different channels, adjust this line accordingly\n",
    "        self.resnet101.conv1 = nn.Conv2d(config.channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        num_features = self.resnet101.fc.in_features\n",
    "        self.resnet101.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet101(x)\n",
    "    \n",
    "\n",
    "    \n",
    "class ModifiedResnet50_Classifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ModifiedResnet50_Classifier, self).__init__()\n",
    "        \n",
    "        # Load the pretrained ResNet-50 model\n",
    "        self.resnet50 = models.resnet50(pretrained=True)\n",
    "        \n",
    "        # Modify the first convolutional layer\n",
    "        self.resnet50.conv1 = nn.Conv2d(config.channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        \n",
    "        # Remove the final fully connected layer\n",
    "        self.resnet50.fc = nn.Identity()  # Set the final layer to an identity mapping\n",
    "        \n",
    "        # Define the custom fully connected layers\n",
    "        num_features = 2048 \n",
    "        self.fc1 = nn.Linear(num_features, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet50(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  4248\n",
      "Val size:  472\n"
     ]
    }
   ],
   "source": [
    "#------Datasplit\n",
    "# Load the dataframe\n",
    "labels_file = pd.read_csv('./data/labeled_ADSMI/labels_int.csv', index_col=0)\n",
    "train_df, val_df = train_test_split(labels_file, test_size=0.1, stratify=labels_file['Label_int'], random_state=42)\n",
    "# train test split\n",
    "print(\"Train size: \", len(train_df))\n",
    "print(\"Val size: \", len(val_df))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#------Data fold generation for cross-validation\n",
    "n_folds = 8\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Fold:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:42<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.6067\n",
      "Test Accuracy: 69.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:40<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: 0.8554\n",
      "Test Accuracy: 68.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:40<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: 0.5166\n",
      "Test Accuracy: 81.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:40<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: 0.3514\n",
      "Test Accuracy: 86.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:40<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 0.3492\n",
      "Test Accuracy: 82.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:40<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: 0.3201\n",
      "Test Accuracy: 85.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:40<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: 0.1672\n",
      "Test Accuracy: 87.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:40<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: 0.6093\n",
      "Test Accuracy: 83.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:39<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Loss: 0.2964\n",
      "Test Accuracy: 86.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:39<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: 0.4428\n",
      "Test Accuracy: 87.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:39<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Loss: 0.3945\n",
      "Test Accuracy: 81.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:39<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Loss: 0.2385\n",
      "Test Accuracy: 89.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:39<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Loss: 0.2447\n",
      "Test Accuracy: 87.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:39<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Loss: 0.5024\n",
      "Test Accuracy: 88.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:39<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Loss: 0.1722\n",
      "Test Accuracy: 88.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:39<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: 0.3715\n",
      "Test Accuracy: 88.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:39<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Loss: 0.4280\n",
      "Test Accuracy: 89.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:40<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00018: reducing learning rate of group 0 to 3.2000e-04.\n",
      "Epoch [18/20], Loss: 0.2576\n",
      "Test Accuracy: 89.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:40<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Loss: 0.4193\n",
      "Test Accuracy: 89.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:40<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: 0.2803\n",
      "Test Accuracy: 88.94%\n",
      "Fold:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:40<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.1717\n",
      "Test Accuracy: 90.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:40<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: 0.2670\n",
      "Test Accuracy: 89.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:40<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: 0.6323\n",
      "Test Accuracy: 90.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:40<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: 0.1337\n",
      "Test Accuracy: 88.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:40<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 0.1826\n",
      "Test Accuracy: 91.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:40<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: 0.4640\n",
      "Test Accuracy: 89.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:40<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: 0.5755\n",
      "Test Accuracy: 88.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:39<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: 0.3719\n",
      "Test Accuracy: 89.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 42/133 [00:13<00:28,  3.19it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Gabriel\\OneDrive\\Dokumente\\GitHub\\MA-pre-work\\Test_from_scratch\\SA_Notebook_CV.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/SA_Notebook_CV.ipynb#W6sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m train_losses\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/SA_Notebook_CV.ipynb#W6sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# Backward pass and optimization\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/SA_Notebook_CV.ipynb#W6sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m optimizer\u001b[39m.\u001b[39;49mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/SA_Notebook_CV.ipynb#W6sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/SA_Notebook_CV.ipynb#W6sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\optim\\optimizer.py:435\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[1;34m(self, set_to_none)\u001b[0m\n\u001b[0;32m    431\u001b[0m     param_groups \u001b[39m=\u001b[39m [\n\u001b[0;32m    432\u001b[0m         update_group(g, ng) \u001b[39mfor\u001b[39;00m g, ng \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(groups, saved_groups)]\n\u001b[0;32m    433\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__setstate__({\u001b[39m'\u001b[39m\u001b[39mstate\u001b[39m\u001b[39m'\u001b[39m: state, \u001b[39m'\u001b[39m\u001b[39mparam_groups\u001b[39m\u001b[39m'\u001b[39m: param_groups})\n\u001b[1;32m--> 435\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mzero_grad\u001b[39m(\u001b[39mself\u001b[39m, set_to_none: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    436\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sets the gradients of all optimized :class:`torch.Tensor` s to zero.\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \n\u001b[0;32m    438\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[39m            the step altogether).\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m    450\u001b[0m     foreach \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mforeach\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "num_classes = len(set(labels_file[\"Label_int\"]))  # Assuming the number of classes is the unique count of \"Label_int\" in your labels_file\n",
    "#model = Resnet50_Classifier(num_classes)\n",
    "model = ModifiedResnet50_Classifier(num_classes)\n",
    "#model = ResNet101_Classifier(num_classes)\n",
    "\n",
    "\n",
    "\n",
    "#  Transfer the model to the appropriate device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model.to(device)\n",
    "\n",
    "# Define a loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0004, weight_decay = 1e-4 ) # Adjust the value as needed)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=10, factor=0.8, verbose=True)\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "config.best_accuracy = 0\n",
    "config.model_path = \"./results_standalone/test2_checkpoint.pth\"\n",
    "\n",
    "\n",
    "for fold, (train_indices, test_indices) in enumerate(skf.split(train_df, train_df['Label_int'])):\n",
    "    \n",
    "    train_loader, test_loader = DL.create_generators_finetune(train_df=train_df,train_indices=train_indices, test_indices=test_indices)\n",
    "    #  Create an instance of the model\n",
    "    \n",
    "    # Training loop\n",
    "    print(\"Fold: \", fold)\n",
    "    num_epochs = 20  # Adjust this as needed\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch_idx, (spectrograms, labels) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "            spectrograms = spectrograms.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(spectrograms)\n",
    "            loss = criterion(outputs, labels)\n",
    "            train_losses.append(loss.item())\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        # Set the model to evaluation mode (important for dropout and batch normalization)\n",
    "        model.eval()\n",
    "\n",
    "        # Iterate through the test set\n",
    "        with torch.no_grad():  # Disable gradient computation during testing\n",
    "            for spectrograms, labels in test_loader:\n",
    "                # Move data to the testing device\n",
    "                spectrograms = spectrograms.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(spectrograms)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_losses.append(loss.item())\n",
    "                \n",
    "                # Compute the predicted labels\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                # Update evaluation metrics\n",
    "                total_samples += labels.size(0)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        #if new test accuracy is better than the previous best, save the model\n",
    "        if correct_predictions / total_samples > config.best_accuracy:\n",
    "            config.best_accuracy = correct_predictions / total_samples\n",
    "            torch.save(model, config.model_path)\n",
    "            \n",
    "        # Step the learning rate scheduler\n",
    "        scheduler.step(test_losses[-1])\n",
    "\n",
    "        # Calculate accuracy or other evaluation metrics\n",
    "        accuracy = correct_predictions / total_samples\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "        print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Gabriel\\OneDrive\\Dokumente\\GitHub\\MA-pre-work\\Test_from_scratch\\SA_Notebook_CV.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/SA_Notebook_CV.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/SA_Notebook_CV.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m classification_report, confusion_matrix, precision_recall_fscore_support\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/SA_Notebook_CV.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m config\u001b[39m.\u001b[39mdesired_length_in_seconds \u001b[39m=\u001b[39m \u001b[39m15\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/SA_Notebook_CV.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Set the device for testing\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/SA_Notebook_CV.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "config.desired_length_in_seconds = 15\n",
    "\n",
    "# Set the device for testing\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create a data loader for the test set\n",
    "val_loader = DL.create_generators_finetune_val(val_df=val_df,)  # Assuming create_generators_finetune returns (train_loader, test_loader)\n",
    "\n",
    "\n",
    "#model = torch.load(config.model_path)\n",
    "# Transfer the model to the testing device\n",
    "model.to(device)\n",
    "\n",
    "# Define a criterion for evaluation (e.g., cross-entropy loss for classification)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize variables for evaluation metrics (e.g., accuracy)\n",
    "correct_predictions = 0\n",
    "total_samples = 0\n",
    "\n",
    "# Define the label dictionary\n",
    "true_labels_dic = {0: '[Kreischen]', 1: '[Kreischen][Quietschen]', 2: '[Negativ]', 3: '[Quietschen]'}\n",
    "\n",
    "# Set the model to evaluation mode (important for dropout and batch normalization)\n",
    "model.eval()\n",
    "\n",
    "# Initialize lists to store all true labels and predicted labels\n",
    "all_true_labels = []\n",
    "all_predicted_labels = []\n",
    "\n",
    "# Iterate through the test set\n",
    "with torch.no_grad():\n",
    "    for spectrograms, labels in val_loader:\n",
    "        # Move data to the testing device\n",
    "        spectrograms = spectrograms.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(spectrograms)\n",
    "        \n",
    "        # Compute the predicted labels\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Append true and predicted labels to the lists\n",
    "        all_true_labels.extend(labels.cpu().numpy())\n",
    "        all_predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_true_labels = np.array(all_true_labels)\n",
    "all_predicted_labels = np.array(all_predicted_labels)\n",
    "\n",
    "# Calculate accuracy, precision, recall, F1-score, etc. using all_true_labels and all_predicted_labels\n",
    "accuracy = np.mean(all_true_labels == all_predicted_labels)\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(all_true_labels, all_predicted_labels, average='weighted')\n",
    "_, recall_per_class, _, _ = precision_recall_fscore_support(all_true_labels, all_predicted_labels)\n",
    "\n",
    "\n",
    "\n",
    "#calculate balanced accuracy\n",
    "balanced_accuracy = np.mean(recall_per_class)\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy * 100:.2f}%\")\n",
    "\n",
    "print(f\"Val Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"\\nEvaluation Results:\")\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "conf_mat = confusion_matrix(all_true_labels, all_predicted_labels)\n",
    "def plot_confusion_matrix(conf_mat, class_labels):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.set(font_scale=1.2)\n",
    "    \n",
    "    # Convert class_labels to a list of strings (or integers)\n",
    "    class_labels = [str(label) for label in class_labels]\n",
    "    \n",
    "    ax = sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "                xticklabels=class_labels,\n",
    "                yticklabels=class_labels)\n",
    "    \n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xticks(rotation=90)  # Rotate x-axis labels vertically\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(conf_mat, true_labels_dic.values())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
