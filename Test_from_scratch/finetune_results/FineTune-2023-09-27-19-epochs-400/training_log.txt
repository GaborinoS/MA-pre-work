Epoch [1/400] Training Loss: 3.7922, Validation Loss: 3.8993
Epoch [2/400] Training Loss: 3.1377, Validation Loss: 4.1400
Epoch [3/400] Training Loss: 2.9371, Validation Loss: 3.3366
Epoch [4/400] Training Loss: 2.7205, Validation Loss: 2.9613
Epoch [5/400] Training Loss: 2.6163, Validation Loss: 2.8899
Epoch [6/400] Training Loss: 2.4194, Validation Loss: 2.5416
Epoch [7/400] Training Loss: 2.2386, Validation Loss: 2.8545
Epoch [8/400] Training Loss: 2.1964, Validation Loss: 2.8873
Epoch [9/400] Training Loss: 2.1051, Validation Loss: 2.5346
Epoch [10/400] Training Loss: 1.9708, Validation Loss: 2.4515
Epoch [11/400] Training Loss: 1.9406, Validation Loss: 3.3270
Epoch [12/400] Training Loss: 1.8787, Validation Loss: 2.4742
Epoch [13/400] Training Loss: 1.7831, Validation Loss: 2.5015
Epoch [14/400] Training Loss: 1.6745, Validation Loss: 2.1768
Epoch [15/400] Training Loss: 1.5607, Validation Loss: 2.1948
Epoch [16/400] Training Loss: 1.5578, Validation Loss: 2.5015
Epoch [17/400] Training Loss: 1.5210, Validation Loss: 2.4861
Epoch [18/400] Training Loss: 1.3504, Validation Loss: 2.1744
Epoch [19/400] Training Loss: 1.3219, Validation Loss: 2.2347
Epoch [20/400] Training Loss: 1.3566, Validation Loss: 3.3983
Epoch [21/400] Training Loss: 1.2357, Validation Loss: 2.4057
Epoch [22/400] Training Loss: 1.2469, Validation Loss: 2.1939
Epoch [23/400] Training Loss: 1.1692, Validation Loss: 1.9481
Epoch [24/400] Training Loss: 1.0683, Validation Loss: 3.8526
Epoch [25/400] Training Loss: 1.0798, Validation Loss: 2.1894
Epoch [26/400] Training Loss: 0.9420, Validation Loss: 1.8817
Epoch [27/400] Training Loss: 0.9365, Validation Loss: 2.1841
Epoch [28/400] Training Loss: 0.9184, Validation Loss: 1.6991
Epoch [29/400] Training Loss: 0.8375, Validation Loss: 3.0617
Epoch [30/400] Training Loss: 0.7858, Validation Loss: 2.0753
Epoch [31/400] Training Loss: 0.7941, Validation Loss: 3.8085
Epoch [32/400] Training Loss: 0.8030, Validation Loss: 1.7809
Epoch [33/400] Training Loss: 0.7215, Validation Loss: 1.9991
Epoch [34/400] Training Loss: 0.7491, Validation Loss: 2.9679
Epoch [35/400] Training Loss: 0.6692, Validation Loss: 2.7824
Epoch [36/400] Training Loss: 0.6472, Validation Loss: 4.6762
Epoch [37/400] Training Loss: 0.7740, Validation Loss: 2.4823
Epoch [38/400] Training Loss: 0.6748, Validation Loss: 1.5528
Epoch [39/400] Training Loss: 0.6313, Validation Loss: 1.8060
Epoch [40/400] Training Loss: 0.5773, Validation Loss: 1.4057
Epoch [41/400] Training Loss: 0.5209, Validation Loss: 1.7242
Epoch [42/400] Training Loss: 0.5335, Validation Loss: 1.4874
Epoch [43/400] Training Loss: 0.5346, Validation Loss: 1.6544
Epoch [44/400] Training Loss: 0.4967, Validation Loss: 1.6407
Epoch [45/400] Training Loss: 0.5165, Validation Loss: 1.3195
Epoch [46/400] Training Loss: 0.5341, Validation Loss: 4.2789
Epoch [47/400] Training Loss: 0.5282, Validation Loss: 1.6350
Epoch [48/400] Training Loss: 0.5442, Validation Loss: 2.0569
Epoch [49/400] Training Loss: 0.4756, Validation Loss: 2.2445
Epoch [50/400] Training Loss: 0.4705, Validation Loss: 1.8158
Epoch [51/400] Training Loss: 0.4337, Validation Loss: 2.3405
Epoch [52/400] Training Loss: 0.3917, Validation Loss: 1.4252
Epoch [53/400] Training Loss: 0.4214, Validation Loss: 4.0245
Epoch [54/400] Training Loss: 0.4294, Validation Loss: 3.8144
Epoch [55/400] Training Loss: 0.4211, Validation Loss: 2.4698
Epoch [56/400] Training Loss: 0.4018, Validation Loss: 1.9477
Epoch [57/400] Training Loss: 0.4788, Validation Loss: 1.6023
Epoch [58/400] Training Loss: 0.3972, Validation Loss: 1.3755
Epoch [59/400] Training Loss: 0.4072, Validation Loss: 2.6175
Epoch [60/400] Training Loss: 0.3758, Validation Loss: 4.7166
Epoch [61/400] Training Loss: 0.3831, Validation Loss: 1.5555
Epoch [62/400] Training Loss: 0.3885, Validation Loss: 1.9522
Epoch [63/400] Training Loss: 0.4290, Validation Loss: 2.3323
Epoch [64/400] Training Loss: 0.3615, Validation Loss: 1.9213
Epoch [65/400] Training Loss: 0.3344, Validation Loss: 1.4563
Epoch [66/400] Training Loss: 0.3567, Validation Loss: 1.8823
Epoch [67/400] Training Loss: 0.3309, Validation Loss: 1.9411
Epoch [68/400] Training Loss: 0.2835, Validation Loss: 1.7148
Epoch [69/400] Training Loss: 0.2674, Validation Loss: 1.5997
Epoch [70/400] Training Loss: 0.3042, Validation Loss: 1.9341
Epoch [71/400] Training Loss: 0.3162, Validation Loss: 1.2925
Epoch [72/400] Training Loss: 0.2726, Validation Loss: 1.6949
Epoch [73/400] Training Loss: 0.2774, Validation Loss: 2.0158
Epoch [74/400] Training Loss: 0.2286, Validation Loss: 1.5109
Epoch [75/400] Training Loss: 0.2819, Validation Loss: 2.6212
Epoch [76/400] Training Loss: 0.3642, Validation Loss: 1.7928
Epoch [77/400] Training Loss: 0.3750, Validation Loss: 2.6197
Epoch [78/400] Training Loss: 0.3350, Validation Loss: 1.9283
Epoch [79/400] Training Loss: 0.3005, Validation Loss: 1.8521
Epoch [80/400] Training Loss: 0.2152, Validation Loss: 1.6502
Epoch [81/400] Training Loss: 0.2576, Validation Loss: 1.5615
Epoch [82/400] Training Loss: 0.2645, Validation Loss: 1.4791
Epoch [83/400] Training Loss: 0.2971, Validation Loss: 1.2571
Epoch [84/400] Training Loss: 0.2829, Validation Loss: 1.6433
Epoch [85/400] Training Loss: 0.2440, Validation Loss: 1.8273
Epoch [86/400] Training Loss: 0.2417, Validation Loss: 1.3283
Epoch [87/400] Training Loss: 0.2222, Validation Loss: 2.0615
Epoch [88/400] Training Loss: 0.2335, Validation Loss: 2.1615
Epoch [89/400] Training Loss: 0.2102, Validation Loss: 3.8193
Epoch [90/400] Training Loss: 0.2302, Validation Loss: 1.5798
Epoch [91/400] Training Loss: 0.2260, Validation Loss: 1.5290
Epoch [92/400] Training Loss: 0.2499, Validation Loss: 2.3839
Epoch [93/400] Training Loss: 0.2580, Validation Loss: 1.7398
Epoch [94/400] Training Loss: 0.2317, Validation Loss: 1.5635
Epoch [95/400] Training Loss: 0.2857, Validation Loss: 1.8271
Epoch [96/400] Training Loss: 0.2259, Validation Loss: 1.6749
Epoch [97/400] Training Loss: 0.2036, Validation Loss: 1.8913
Epoch [98/400] Training Loss: 0.2490, Validation Loss: 2.4268
Epoch [99/400] Training Loss: 0.2467, Validation Loss: 1.9500
Epoch [100/400] Training Loss: 0.2612, Validation Loss: 4.9162
Epoch [101/400] Training Loss: 0.2378, Validation Loss: 1.6352
Epoch [102/400] Training Loss: 0.2077, Validation Loss: 2.2784
Epoch [103/400] Training Loss: 0.2695, Validation Loss: 2.2238
Epoch [104/400] Training Loss: 0.2000, Validation Loss: 1.6053
Epoch [105/400] Training Loss: 0.1468, Validation Loss: 3.1917
Epoch [106/400] Training Loss: 0.2023, Validation Loss: 2.6315
Epoch [107/400] Training Loss: 0.1897, Validation Loss: 2.8562
Epoch [108/400] Training Loss: 0.1920, Validation Loss: 2.8521
Epoch [109/400] Training Loss: 0.1995, Validation Loss: 1.4986
Epoch [110/400] Training Loss: 0.2379, Validation Loss: 2.2780
Epoch [111/400] Training Loss: 0.2083, Validation Loss: 1.8383
Epoch [112/400] Training Loss: 0.2741, Validation Loss: 1.7000
Epoch [113/400] Training Loss: 0.2575, Validation Loss: 2.3666
Epoch [114/400] Training Loss: 0.2608, Validation Loss: 2.3420
Epoch [115/400] Training Loss: 0.2518, Validation Loss: 2.7755
Epoch [116/400] Training Loss: 0.1711, Validation Loss: 1.6933
Epoch [117/400] Training Loss: 0.1969, Validation Loss: 1.5182
Epoch [118/400] Training Loss: 0.1754, Validation Loss: 1.5411
Epoch [119/400] Training Loss: 0.1481, Validation Loss: 1.4951
Epoch [120/400] Training Loss: 0.1878, Validation Loss: 1.7752
Epoch [121/400] Training Loss: 0.2273, Validation Loss: 1.6883
Epoch [122/400] Training Loss: 0.1539, Validation Loss: 1.7415
Epoch [123/400] Training Loss: 0.2467, Validation Loss: 2.1914
Epoch [124/400] Training Loss: 0.2904, Validation Loss: 3.8126
Epoch [125/400] Training Loss: 0.2509, Validation Loss: 1.7754
Epoch [126/400] Training Loss: 0.1563, Validation Loss: 1.4203
Epoch [127/400] Training Loss: 0.2141, Validation Loss: 1.9369
Epoch [128/400] Training Loss: 0.1500, Validation Loss: 1.4050
Epoch [129/400] Training Loss: 0.1697, Validation Loss: 2.3856
Epoch [130/400] Training Loss: 0.1718, Validation Loss: 1.4195
Epoch [131/400] Training Loss: 0.1527, Validation Loss: 2.3162
Epoch [132/400] Training Loss: 0.1848, Validation Loss: 4.0644
Epoch [133/400] Training Loss: 0.1845, Validation Loss: 1.6471
Epoch [134/400] Training Loss: 0.1567, Validation Loss: 1.6479
Epoch [135/400] Training Loss: 0.1528, Validation Loss: 1.3776
Epoch [136/400] Training Loss: 0.1925, Validation Loss: 4.4669
Epoch [137/400] Training Loss: 0.1765, Validation Loss: 1.5468
Epoch [138/400] Training Loss: 0.1399, Validation Loss: 2.6146
Epoch [139/400] Training Loss: 0.1979, Validation Loss: 2.2163
Epoch [140/400] Training Loss: 0.1484, Validation Loss: 1.5455
Epoch [141/400] Training Loss: 0.1106, Validation Loss: 1.8184
Epoch [142/400] Training Loss: 0.1444, Validation Loss: 1.7234
