Epoch [1/400] Training Loss: 3.5480, Validation Loss: 3.8265
Epoch [2/400] Training Loss: 2.9273, Validation Loss: 4.8461
Epoch [3/400] Training Loss: 2.6710, Validation Loss: 2.8351
Epoch [4/400] Training Loss: 2.5100, Validation Loss: 2.6180
Epoch [5/400] Training Loss: 2.1855, Validation Loss: 2.8199
Epoch [6/400] Training Loss: 2.0177, Validation Loss: 2.3494
Epoch [7/400] Training Loss: 1.8511, Validation Loss: 2.6340
Epoch [8/400] Training Loss: 1.7256, Validation Loss: 2.3608
Epoch [9/400] Training Loss: 1.6094, Validation Loss: 2.4394
Epoch [10/400] Training Loss: 1.4814, Validation Loss: 2.6666
Epoch [11/400] Training Loss: 1.4744, Validation Loss: 1.9329
Epoch [12/400] Training Loss: 1.3205, Validation Loss: 2.2175
Epoch [13/400] Training Loss: 1.1614, Validation Loss: 2.0270
Epoch [14/400] Training Loss: 1.0748, Validation Loss: 2.4127
Epoch [15/400] Training Loss: 0.9888, Validation Loss: 1.8962
Epoch [16/400] Training Loss: 0.9165, Validation Loss: 1.8858
Epoch [17/400] Training Loss: 0.8813, Validation Loss: 1.6506
Epoch [18/400] Training Loss: 0.8404, Validation Loss: 1.7664
Epoch [19/400] Training Loss: 0.8278, Validation Loss: 2.1522
Epoch [20/400] Training Loss: 0.7173, Validation Loss: 1.8382
Epoch [21/400] Training Loss: 0.6279, Validation Loss: 2.1607
Epoch [22/400] Training Loss: 0.6331, Validation Loss: 2.0729
Epoch [23/400] Training Loss: 0.6171, Validation Loss: 3.3436
Epoch [24/400] Training Loss: 0.5773, Validation Loss: 1.8785
Epoch [25/400] Training Loss: 0.5863, Validation Loss: 1.7032
Epoch [26/400] Training Loss: 0.4956, Validation Loss: 1.5056
Epoch [27/400] Training Loss: 0.4771, Validation Loss: 1.8301
Epoch [28/400] Training Loss: 0.4950, Validation Loss: 1.6552
Epoch [29/400] Training Loss: 0.4119, Validation Loss: 2.5722
Epoch [30/400] Training Loss: 0.4258, Validation Loss: 1.7494
Epoch [31/400] Training Loss: 0.3797, Validation Loss: 1.5238
Epoch [32/400] Training Loss: 0.3739, Validation Loss: 1.8516
Epoch [33/400] Training Loss: 0.4285, Validation Loss: 2.0509
Epoch [34/400] Training Loss: 0.3638, Validation Loss: 1.6527
Epoch [35/400] Training Loss: 0.2816, Validation Loss: 1.5844
Epoch [36/400] Training Loss: 0.3045, Validation Loss: 1.6352
Epoch [37/400] Training Loss: 0.3379, Validation Loss: 1.9051
Epoch [38/400] Training Loss: 0.3240, Validation Loss: 2.4338
Epoch [39/400] Training Loss: 0.3117, Validation Loss: 1.5502
Epoch [40/400] Training Loss: 0.3171, Validation Loss: 1.5944
Epoch [41/400] Training Loss: 0.3440, Validation Loss: 2.2259
Epoch [42/400] Training Loss: 0.2780, Validation Loss: 1.3619
Epoch [43/400] Training Loss: 0.2642, Validation Loss: 1.6610
Epoch [44/400] Training Loss: 0.2456, Validation Loss: 1.7117
Epoch [45/400] Training Loss: 0.2330, Validation Loss: 1.5393
Epoch [46/400] Training Loss: 0.2102, Validation Loss: 1.3088
Epoch [47/400] Training Loss: 0.2597, Validation Loss: 1.9536
Epoch [48/400] Training Loss: 0.2439, Validation Loss: 1.8530
Epoch [49/400] Training Loss: 0.2496, Validation Loss: 2.0884
Epoch [50/400] Training Loss: 0.3001, Validation Loss: 2.2067
Epoch [51/400] Training Loss: 0.2818, Validation Loss: 1.9316
Epoch [52/400] Training Loss: 0.2776, Validation Loss: 1.5499
Epoch [53/400] Training Loss: 0.1724, Validation Loss: 2.1900
Epoch [54/400] Training Loss: 0.1662, Validation Loss: 1.8687
Epoch [55/400] Training Loss: 0.1785, Validation Loss: 1.5243
Epoch [56/400] Training Loss: 0.2121, Validation Loss: 1.8506
Epoch [57/400] Training Loss: 0.2085, Validation Loss: 2.5600
Epoch [58/400] Training Loss: 0.1932, Validation Loss: 1.7302
Epoch [59/400] Training Loss: 0.1667, Validation Loss: 1.7305
Epoch [60/400] Training Loss: 0.1386, Validation Loss: 1.5192
Epoch [61/400] Training Loss: 0.1616, Validation Loss: 1.5781
Epoch [62/400] Training Loss: 0.1680, Validation Loss: 1.5035
Epoch [63/400] Training Loss: 0.1732, Validation Loss: 1.5757
Epoch [64/400] Training Loss: 0.1879, Validation Loss: 1.6170
Epoch [65/400] Training Loss: 0.1871, Validation Loss: 2.0595
Epoch [66/400] Training Loss: 0.2212, Validation Loss: 2.9515
Epoch [67/400] Training Loss: 0.1792, Validation Loss: 1.9236
Epoch [68/400] Training Loss: 0.1454, Validation Loss: 2.3003
Epoch [69/400] Training Loss: 0.1460, Validation Loss: 2.0894
Epoch [70/400] Training Loss: 0.1560, Validation Loss: 1.5135
Epoch [71/400] Training Loss: 0.1694, Validation Loss: 1.8062
Epoch [72/400] Training Loss: 0.1663, Validation Loss: 1.9999
Epoch [73/400] Training Loss: 0.1739, Validation Loss: 2.1347
Epoch [74/400] Training Loss: 0.1889, Validation Loss: 3.6643
Epoch [75/400] Training Loss: 0.1620, Validation Loss: 1.9142
Epoch [76/400] Training Loss: 0.1979, Validation Loss: 1.9917
Epoch [77/400] Training Loss: 0.2168, Validation Loss: 2.1378
Epoch [78/400] Training Loss: 0.1328, Validation Loss: 1.5481
Epoch [79/400] Training Loss: 0.1762, Validation Loss: 1.6773
Epoch [80/400] Training Loss: 0.1727, Validation Loss: 2.0645
Epoch [81/400] Training Loss: 0.2074, Validation Loss: 2.1092
Epoch [82/400] Training Loss: 0.1677, Validation Loss: 1.6705
Epoch [83/400] Training Loss: 0.1474, Validation Loss: 1.3557
Epoch [84/400] Training Loss: 0.1203, Validation Loss: 2.0284
Epoch [85/400] Training Loss: 0.1452, Validation Loss: 1.6769
Epoch [86/400] Training Loss: 0.1254, Validation Loss: 1.6938
Epoch [87/400] Training Loss: 0.1335, Validation Loss: 2.3033
Epoch [88/400] Training Loss: 0.1118, Validation Loss: 2.7236
Epoch [89/400] Training Loss: 0.1006, Validation Loss: 1.6423
Epoch [90/400] Training Loss: 0.1093, Validation Loss: 1.8395
Epoch [91/400] Training Loss: 0.0895, Validation Loss: 1.8871
Epoch [92/400] Training Loss: 0.1121, Validation Loss: 1.8159
Epoch [93/400] Training Loss: 0.1321, Validation Loss: 2.4287
Epoch [94/400] Training Loss: 0.1166, Validation Loss: 2.2033
Epoch [95/400] Training Loss: 0.0818, Validation Loss: 1.8953
Epoch [96/400] Training Loss: 0.0533, Validation Loss: 1.1508
Epoch [97/400] Training Loss: 0.0564, Validation Loss: 1.4471
Epoch [98/400] Training Loss: 0.0769, Validation Loss: 1.5232
Epoch [99/400] Training Loss: 0.1116, Validation Loss: 1.6724
Epoch [100/400] Training Loss: 0.1364, Validation Loss: 2.3024
Epoch [101/400] Training Loss: 0.1443, Validation Loss: 1.8980
Epoch [102/400] Training Loss: 0.1076, Validation Loss: 1.3760
Epoch [103/400] Training Loss: 0.0836, Validation Loss: 2.1514
Epoch [104/400] Training Loss: 0.0843, Validation Loss: 1.7598
Epoch [105/400] Training Loss: 0.1180, Validation Loss: 2.8296
Epoch [106/400] Training Loss: 0.1190, Validation Loss: 1.5928
Epoch [107/400] Training Loss: 0.1333, Validation Loss: 1.4116
Epoch [108/400] Training Loss: 0.1374, Validation Loss: 2.1931
Epoch [109/400] Training Loss: 0.1172, Validation Loss: 4.3845
Epoch [110/400] Training Loss: 0.1145, Validation Loss: 1.7747
Epoch [111/400] Training Loss: 0.0850, Validation Loss: 1.6157
Epoch [112/400] Training Loss: 0.0968, Validation Loss: 2.1338
Epoch [113/400] Training Loss: 0.0981, Validation Loss: 1.7994
Epoch [114/400] Training Loss: 0.0962, Validation Loss: 2.1084
Epoch [115/400] Training Loss: 0.0903, Validation Loss: 1.7336
Epoch [116/400] Training Loss: 0.1245, Validation Loss: 3.5441
Epoch [117/400] Training Loss: 0.1170, Validation Loss: 1.8997
Epoch [118/400] Training Loss: 0.1212, Validation Loss: 2.0879
Epoch [119/400] Training Loss: 0.1282, Validation Loss: 1.6884
Epoch [120/400] Training Loss: 0.1255, Validation Loss: 1.9150
Epoch [121/400] Training Loss: 0.1156, Validation Loss: 2.9869
Epoch [122/400] Training Loss: 0.1187, Validation Loss: 1.7674
Epoch [123/400] Training Loss: 0.1497, Validation Loss: 4.4023
Epoch [124/400] Training Loss: 0.1308, Validation Loss: 1.7514
Epoch [125/400] Training Loss: 0.0713, Validation Loss: 1.8645
Epoch [126/400] Training Loss: 0.0668, Validation Loss: 3.1088
Epoch [127/400] Training Loss: 0.0887, Validation Loss: 2.4125
Epoch [128/400] Training Loss: 0.1106, Validation Loss: 2.1674
Epoch [129/400] Training Loss: 0.1091, Validation Loss: 2.0776
Epoch [130/400] Training Loss: 0.0729, Validation Loss: 1.7070
Epoch [131/400] Training Loss: 0.0924, Validation Loss: 3.3939
Epoch [132/400] Training Loss: 0.1368, Validation Loss: 2.2906
Epoch [133/400] Training Loss: 0.1491, Validation Loss: 2.1912
Epoch [134/400] Training Loss: 0.1481, Validation Loss: 3.2734
Epoch [135/400] Training Loss: 0.1118, Validation Loss: 1.8571
Epoch [136/400] Training Loss: 0.1066, Validation Loss: 1.9029
Epoch [137/400] Training Loss: 0.1134, Validation Loss: 2.1902
Epoch [138/400] Training Loss: 0.0785, Validation Loss: 1.3165
Epoch [139/400] Training Loss: 0.0908, Validation Loss: 1.8773
Epoch [140/400] Training Loss: 0.1185, Validation Loss: 2.1193
Epoch [141/400] Training Loss: 0.1117, Validation Loss: 1.8121
Epoch [142/400] Training Loss: 0.0992, Validation Loss: 1.7397
Epoch [143/400] Training Loss: 0.0744, Validation Loss: 1.6750
Epoch [144/400] Training Loss: 0.0794, Validation Loss: 1.6723
Epoch [145/400] Training Loss: 0.0987, Validation Loss: 2.3336
Epoch [146/400] Training Loss: 0.0961, Validation Loss: 1.6391
Epoch [147/400] Training Loss: 0.1264, Validation Loss: 2.2503
Epoch [148/400] Training Loss: 0.1001, Validation Loss: 3.9627
Epoch [149/400] Training Loss: 0.1535, Validation Loss: 1.6868
Epoch [150/400] Training Loss: 0.1325, Validation Loss: 1.8923
Epoch [151/400] Training Loss: 0.1070, Validation Loss: 2.2300
Epoch [152/400] Training Loss: 0.0828, Validation Loss: 2.2237
Epoch [153/400] Training Loss: 0.0987, Validation Loss: 1.9126
Epoch [154/400] Training Loss: 0.1010, Validation Loss: 1.7919
Epoch [155/400] Training Loss: 0.0849, Validation Loss: 2.1332
Epoch [156/400] Training Loss: 0.0742, Validation Loss: 2.3631
Epoch [157/400] Training Loss: 0.0493, Validation Loss: 1.6088
Epoch [158/400] Training Loss: 0.0598, Validation Loss: 1.4277
Epoch [159/400] Training Loss: 0.0865, Validation Loss: 1.8863
Epoch [160/400] Training Loss: 0.0950, Validation Loss: 1.7533
Epoch [161/400] Training Loss: 0.0990, Validation Loss: 2.1105
Epoch [162/400] Training Loss: 0.0797, Validation Loss: 2.6255
Epoch [163/400] Training Loss: 0.0907, Validation Loss: 3.0212
Epoch [164/400] Training Loss: 0.1142, Validation Loss: 2.6802
Epoch [165/400] Training Loss: 0.1203, Validation Loss: 2.8622
Epoch [166/400] Training Loss: 0.1109, Validation Loss: 2.4159
Epoch [167/400] Training Loss: 0.0929, Validation Loss: 1.9083
Epoch [168/400] Training Loss: 0.1144, Validation Loss: 2.3243
Epoch [169/400] Training Loss: 0.1094, Validation Loss: 1.6610
Epoch [170/400] Training Loss: 0.1242, Validation Loss: 2.7124
Epoch [171/400] Training Loss: 0.1047, Validation Loss: 1.6932
Epoch [172/400] Training Loss: 0.0595, Validation Loss: 1.4086
Epoch [173/400] Training Loss: 0.1010, Validation Loss: 1.6701
Epoch [174/400] Training Loss: 0.1028, Validation Loss: 2.3724
Epoch [175/400] Training Loss: 0.0956, Validation Loss: 2.0331
Epoch [176/400] Training Loss: 0.1086, Validation Loss: 2.5238
Epoch [177/400] Training Loss: 0.0723, Validation Loss: 1.7454
Epoch [178/400] Training Loss: 0.0806, Validation Loss: 1.8190
Epoch [179/400] Training Loss: 0.0813, Validation Loss: 1.9756
Epoch [180/400] Training Loss: 0.0729, Validation Loss: 1.7709
Epoch [181/400] Training Loss: 0.0709, Validation Loss: 1.8669
Epoch [182/400] Training Loss: 0.0682, Validation Loss: 1.7261
Epoch [183/400] Training Loss: 0.1275, Validation Loss: 2.2558
Epoch [184/400] Training Loss: 0.1012, Validation Loss: 2.2987
Epoch [185/400] Training Loss: 0.0828, Validation Loss: 2.4515
Epoch [186/400] Training Loss: 0.0771, Validation Loss: 1.6642
Epoch [187/400] Training Loss: 0.0765, Validation Loss: 1.9219
Epoch [188/400] Training Loss: 0.0664, Validation Loss: 1.8902
Epoch [189/400] Training Loss: 0.0940, Validation Loss: 2.7192
Epoch [190/400] Training Loss: 0.1209, Validation Loss: 4.9071
Epoch [191/400] Training Loss: 0.0903, Validation Loss: 2.0235
Epoch [192/400] Training Loss: 0.0894, Validation Loss: 1.7524
Epoch [193/400] Training Loss: 0.0650, Validation Loss: 1.6394
Epoch [194/400] Training Loss: 0.0574, Validation Loss: 1.9543
Epoch [195/400] Training Loss: 0.0695, Validation Loss: 3.3569
Epoch [196/400] Training Loss: 0.0752, Validation Loss: 1.7784
Epoch [197/400] Training Loss: 0.0630, Validation Loss: 1.6000
Epoch [198/400] Training Loss: 0.0500, Validation Loss: 1.7926
Epoch [199/400] Training Loss: 0.0573, Validation Loss: 1.7193
Epoch [200/400] Training Loss: 0.1146, Validation Loss: 1.9212
Epoch [201/400] Training Loss: 0.1076, Validation Loss: 2.6029
Epoch [202/400] Training Loss: 0.0967, Validation Loss: 1.8171
Epoch [203/400] Training Loss: 0.0567, Validation Loss: 1.7185
Epoch [204/400] Training Loss: 0.0784, Validation Loss: 2.4986
Epoch [205/400] Training Loss: 0.0936, Validation Loss: 1.9199
Epoch [206/400] Training Loss: 0.0799, Validation Loss: 1.7245
Epoch [207/400] Training Loss: 0.0877, Validation Loss: 1.9060
Epoch [208/400] Training Loss: 0.1020, Validation Loss: 2.7832
Epoch [209/400] Training Loss: 0.0755, Validation Loss: 2.2016
Epoch [210/400] Training Loss: 0.0710, Validation Loss: 2.0073
Epoch [211/400] Training Loss: 0.0709, Validation Loss: 1.7018
Epoch [212/400] Training Loss: 0.0699, Validation Loss: 1.6637
Epoch [213/400] Training Loss: 0.0433, Validation Loss: 1.6923
Epoch [214/400] Training Loss: 0.0534, Validation Loss: 1.9917
Epoch [215/400] Training Loss: 0.0756, Validation Loss: 2.0133
Epoch [216/400] Training Loss: 0.1075, Validation Loss: 1.7781
Epoch [217/400] Training Loss: 0.0738, Validation Loss: 1.6441
Epoch [218/400] Training Loss: 0.0770, Validation Loss: 1.9558
Epoch [219/400] Training Loss: 0.0413, Validation Loss: 1.4852
Epoch [220/400] Training Loss: 0.0496, Validation Loss: 1.5820
Epoch [221/400] Training Loss: 0.0429, Validation Loss: 2.9418
Epoch [222/400] Training Loss: 0.0682, Validation Loss: 1.7344
Epoch [223/400] Training Loss: 0.0734, Validation Loss: 1.6970
Epoch [224/400] Training Loss: 0.0796, Validation Loss: 1.9666
Epoch [225/400] Training Loss: 0.0950, Validation Loss: 3.1867
Epoch [226/400] Training Loss: 0.0752, Validation Loss: 2.1047
Epoch [227/400] Training Loss: 0.1024, Validation Loss: 1.9831
Epoch [228/400] Training Loss: 0.0918, Validation Loss: 1.9477
Epoch [229/400] Training Loss: 0.1047, Validation Loss: 1.6122
Epoch [230/400] Training Loss: 0.0904, Validation Loss: 1.8372
Epoch [231/400] Training Loss: 0.0568, Validation Loss: 1.4085
Epoch [232/400] Training Loss: 0.0670, Validation Loss: 1.5242
Epoch [233/400] Training Loss: 0.0796, Validation Loss: 2.1500
Epoch [234/400] Training Loss: 0.0645, Validation Loss: 1.8037
Epoch [235/400] Training Loss: 0.0725, Validation Loss: 1.6499
Epoch [236/400] Training Loss: 0.0551, Validation Loss: 1.8687
Epoch [237/400] Training Loss: 0.0487, Validation Loss: 1.6555
Epoch [238/400] Training Loss: 0.0447, Validation Loss: 1.5876
Epoch [239/400] Training Loss: 0.0278, Validation Loss: 1.1997
Epoch [240/400] Training Loss: 0.0212, Validation Loss: 1.6501
Epoch [241/400] Training Loss: 0.0149, Validation Loss: 2.1641
Epoch [242/400] Training Loss: 0.0299, Validation Loss: 1.6398
Epoch [243/400] Training Loss: 0.0294, Validation Loss: 1.5819
Epoch [244/400] Training Loss: 0.0399, Validation Loss: 1.6214
Epoch [245/400] Training Loss: 0.0356, Validation Loss: 1.7019
