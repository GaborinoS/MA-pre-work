Epoch [1/400] Training Loss: 3.5520, Validation Loss: 3.1954
Epoch [2/400] Training Loss: 2.9561, Validation Loss: 3.0715
Epoch [3/400] Training Loss: 2.8288, Validation Loss: 3.0125
Epoch [4/400] Training Loss: 2.6913, Validation Loss: 2.9139
Epoch [5/400] Training Loss: 2.6120, Validation Loss: 2.8915
Epoch [6/400] Training Loss: 2.5797, Validation Loss: 2.8099
Epoch [7/400] Training Loss: 2.4726, Validation Loss: 2.8069
Epoch [8/400] Training Loss: 2.5002, Validation Loss: 2.7845
Epoch [9/400] Training Loss: 2.3464, Validation Loss: 2.7400
Epoch [10/400] Training Loss: 2.3470, Validation Loss: 2.8057
Epoch [11/400] Training Loss: 2.3148, Validation Loss: 2.7791
Epoch [12/400] Training Loss: 2.2406, Validation Loss: 2.7092
Epoch [13/400] Training Loss: 2.2190, Validation Loss: 2.5758
Epoch [14/400] Training Loss: 2.1957, Validation Loss: 2.5737
Epoch [15/400] Training Loss: 2.1332, Validation Loss: 2.5279
Epoch [16/400] Training Loss: 2.0740, Validation Loss: 2.5081
Epoch [17/400] Training Loss: 1.9918, Validation Loss: 2.4542
Epoch [18/400] Training Loss: 2.0202, Validation Loss: 2.4667
Epoch [19/400] Training Loss: 1.9289, Validation Loss: 2.4119
Epoch [20/400] Training Loss: 1.9055, Validation Loss: 2.3913
Epoch [21/400] Training Loss: 1.8500, Validation Loss: 2.3637
Epoch [22/400] Training Loss: 1.8204, Validation Loss: 2.2968
Epoch [23/400] Training Loss: 1.7660, Validation Loss: 2.3643
Epoch [24/400] Training Loss: 1.7291, Validation Loss: 2.1966
Epoch [25/400] Training Loss: 1.6873, Validation Loss: 2.2614
Epoch [26/400] Training Loss: 1.6295, Validation Loss: 2.1568
Epoch [27/400] Training Loss: 1.5979, Validation Loss: 2.2471
Epoch [28/400] Training Loss: 1.6206, Validation Loss: 2.2215
Epoch [29/400] Training Loss: 1.5136, Validation Loss: 2.0238
Epoch [30/400] Training Loss: 1.5104, Validation Loss: 2.1334
Epoch [31/400] Training Loss: 1.4494, Validation Loss: 2.0568
Epoch [32/400] Training Loss: 1.4420, Validation Loss: 1.9956
Epoch [33/400] Training Loss: 1.3654, Validation Loss: 1.9786
Epoch [34/400] Training Loss: 1.3186, Validation Loss: 2.0895
Epoch [35/400] Training Loss: 1.2883, Validation Loss: 2.0199
Epoch [36/400] Training Loss: 1.2385, Validation Loss: 2.0707
Epoch [37/400] Training Loss: 1.1640, Validation Loss: 1.9520
Epoch [38/400] Training Loss: 1.1893, Validation Loss: 1.7511
Epoch [39/400] Training Loss: 1.1577, Validation Loss: 1.7872
Epoch [40/400] Training Loss: 1.0904, Validation Loss: 1.7412
Epoch [41/400] Training Loss: 1.0991, Validation Loss: 1.7910
Epoch [42/400] Training Loss: 1.0103, Validation Loss: 1.7890
Epoch [43/400] Training Loss: 1.0444, Validation Loss: 1.8794
Epoch [44/400] Training Loss: 0.9989, Validation Loss: 1.7935
Epoch [45/400] Training Loss: 0.9844, Validation Loss: 1.7720
Epoch [46/400] Training Loss: 0.9680, Validation Loss: 1.7185
Epoch [47/400] Training Loss: 0.9265, Validation Loss: 1.7431
Epoch [48/400] Training Loss: 0.8792, Validation Loss: 2.0341
Epoch [49/400] Training Loss: 0.8370, Validation Loss: 1.7058
Epoch [50/400] Training Loss: 0.8442, Validation Loss: 1.6711
Epoch [51/400] Training Loss: 0.8158, Validation Loss: 1.7792
Epoch [52/400] Training Loss: 0.7697, Validation Loss: 1.7034
Epoch [53/400] Training Loss: 0.7863, Validation Loss: 1.8817
Epoch [54/400] Training Loss: 0.7366, Validation Loss: 1.6794
Epoch [55/400] Training Loss: 0.7456, Validation Loss: 1.7446
Epoch [56/400] Training Loss: 0.7217, Validation Loss: 1.4493
Epoch [57/400] Training Loss: 0.6653, Validation Loss: 1.6958
Epoch [58/400] Training Loss: 0.6855, Validation Loss: 1.5799
Epoch [59/400] Training Loss: 0.6371, Validation Loss: 1.6466
Epoch [60/400] Training Loss: 0.6550, Validation Loss: 1.4746
Epoch [61/400] Training Loss: 0.6363, Validation Loss: 1.4531
Epoch [62/400] Training Loss: 0.5722, Validation Loss: 1.5856
Epoch [63/400] Training Loss: 0.5528, Validation Loss: 1.4675
Epoch [64/400] Training Loss: 0.6034, Validation Loss: 1.5253
Epoch [65/400] Training Loss: 0.5554, Validation Loss: 1.6465
Epoch [66/400] Training Loss: 0.4995, Validation Loss: 1.4645
Epoch [67/400] Training Loss: 0.5246, Validation Loss: 1.4823
Epoch [68/400] Training Loss: 0.5064, Validation Loss: 1.4176
Epoch [69/400] Training Loss: 0.4711, Validation Loss: 1.4701
Epoch [70/400] Training Loss: 0.4737, Validation Loss: 1.6424
Epoch [71/400] Training Loss: 0.4269, Validation Loss: 1.5499
Epoch [72/400] Training Loss: 0.4938, Validation Loss: 1.6390
Epoch [73/400] Training Loss: 0.4798, Validation Loss: 1.4423
Epoch [74/400] Training Loss: 0.4601, Validation Loss: 1.5367
Epoch [75/400] Training Loss: 0.4546, Validation Loss: 1.3950
Epoch [76/400] Training Loss: 0.4180, Validation Loss: 1.7676
Epoch [77/400] Training Loss: 0.4018, Validation Loss: 1.3756
Epoch [78/400] Training Loss: 0.4254, Validation Loss: 1.5475
Epoch [79/400] Training Loss: 0.4125, Validation Loss: 1.4997
Epoch [80/400] Training Loss: 0.3778, Validation Loss: 1.3660
Epoch [81/400] Training Loss: 0.3993, Validation Loss: 1.6084
Epoch [82/400] Training Loss: 0.3854, Validation Loss: 1.5695
Epoch [83/400] Training Loss: 0.3565, Validation Loss: 1.4879
Epoch [84/400] Training Loss: 0.3400, Validation Loss: 1.5052
Epoch [85/400] Training Loss: 0.3683, Validation Loss: 1.5256
Epoch [86/400] Training Loss: 0.3468, Validation Loss: 1.4084
Epoch [87/400] Training Loss: 0.3467, Validation Loss: 1.7308
Epoch [88/400] Training Loss: 0.3142, Validation Loss: 1.3576
Epoch [89/400] Training Loss: 0.3456, Validation Loss: 1.5848
Epoch [90/400] Training Loss: 0.3441, Validation Loss: 1.5624
Epoch [91/400] Training Loss: 0.2838, Validation Loss: 1.5038
Epoch [92/400] Training Loss: 0.3180, Validation Loss: 1.5256
Epoch [93/400] Training Loss: 0.2916, Validation Loss: 1.4673
Epoch [94/400] Training Loss: 0.2943, Validation Loss: 1.4160
Epoch [95/400] Training Loss: 0.2882, Validation Loss: 1.4369
Epoch [96/400] Training Loss: 0.2762, Validation Loss: 1.5733
Epoch [97/400] Training Loss: 0.2680, Validation Loss: 1.4232
Epoch [98/400] Training Loss: 0.2692, Validation Loss: 1.6217
Epoch [99/400] Training Loss: 0.2340, Validation Loss: 1.3786
Epoch [100/400] Training Loss: 0.3000, Validation Loss: 1.3668
Epoch [101/400] Training Loss: 0.2675, Validation Loss: 2.0056
Epoch [102/400] Training Loss: 0.2755, Validation Loss: 1.5119
Epoch [103/400] Training Loss: 0.2114, Validation Loss: 1.4707
Epoch [104/400] Training Loss: 0.2354, Validation Loss: 1.4860
Epoch [105/400] Training Loss: 0.2503, Validation Loss: 1.4734
Epoch [106/400] Training Loss: 0.2303, Validation Loss: 2.1200
Epoch [107/400] Training Loss: 0.2326, Validation Loss: 1.5875
Epoch [108/400] Training Loss: 0.2300, Validation Loss: 1.4506
Epoch [109/400] Training Loss: 0.2126, Validation Loss: 1.5454
Epoch [110/400] Training Loss: 0.2566, Validation Loss: 1.4538
Epoch [111/400] Training Loss: 0.2449, Validation Loss: 1.4654
Epoch [112/400] Training Loss: 0.2041, Validation Loss: 1.5746
Epoch [113/400] Training Loss: 0.2054, Validation Loss: 1.6345
Epoch [114/400] Training Loss: 0.2379, Validation Loss: 1.6508
Epoch [115/400] Training Loss: 0.2179, Validation Loss: 1.6540
Epoch [116/400] Training Loss: 0.2006, Validation Loss: 1.3357
Epoch [117/400] Training Loss: 0.1922, Validation Loss: 1.5159
Epoch [118/400] Training Loss: 0.2564, Validation Loss: 1.7455
Epoch [119/400] Training Loss: 0.2278, Validation Loss: 1.6529
Epoch [120/400] Training Loss: 0.2413, Validation Loss: 1.6110
Epoch [121/400] Training Loss: 0.1787, Validation Loss: 1.5577
Epoch [122/400] Training Loss: 0.2136, Validation Loss: 1.5735
Epoch [123/400] Training Loss: 0.2056, Validation Loss: 1.5944
Epoch [124/400] Training Loss: 0.2314, Validation Loss: 1.5567
Epoch [125/400] Training Loss: 0.1752, Validation Loss: 1.4496
Epoch [126/400] Training Loss: 0.1584, Validation Loss: 1.4065
Epoch [127/400] Training Loss: 0.1932, Validation Loss: 1.4131
Epoch [128/400] Training Loss: 0.1842, Validation Loss: 1.5551
Epoch [129/400] Training Loss: 0.1866, Validation Loss: 1.7149
Epoch [130/400] Training Loss: 0.1611, Validation Loss: 1.5309
Epoch [131/400] Training Loss: 0.1534, Validation Loss: 1.4294
Epoch [132/400] Training Loss: 0.2115, Validation Loss: 1.6057
Epoch [133/400] Training Loss: 0.1884, Validation Loss: 1.5573
Epoch [134/400] Training Loss: 0.1759, Validation Loss: 1.5272
Epoch [135/400] Training Loss: 0.1788, Validation Loss: 1.4434
Epoch [136/400] Training Loss: 0.2034, Validation Loss: 1.6565
Epoch [137/400] Training Loss: 0.1571, Validation Loss: 1.4896
Epoch [138/400] Training Loss: 0.1745, Validation Loss: 1.7245
Epoch [139/400] Training Loss: 0.1710, Validation Loss: 1.6087
Epoch [140/400] Training Loss: 0.1606, Validation Loss: 1.6130
Epoch [141/400] Training Loss: 0.1713, Validation Loss: 1.6489
Epoch [142/400] Training Loss: 0.1670, Validation Loss: 1.7369
Epoch [143/400] Training Loss: 0.1811, Validation Loss: 1.6046
Epoch [144/400] Training Loss: 0.1555, Validation Loss: 1.6233
Epoch [145/400] Training Loss: 0.1528, Validation Loss: 2.1255
Epoch [146/400] Training Loss: 0.1652, Validation Loss: 1.6458
Epoch [147/400] Training Loss: 0.1456, Validation Loss: 1.5899
Epoch [148/400] Training Loss: 0.1273, Validation Loss: 1.5711
Epoch [149/400] Training Loss: 0.1401, Validation Loss: 1.4228
Epoch [150/400] Training Loss: 0.1704, Validation Loss: 1.9639
Epoch [151/400] Training Loss: 0.1693, Validation Loss: 1.5016
Epoch [152/400] Training Loss: 0.1441, Validation Loss: 1.5968
Epoch [153/400] Training Loss: 0.1903, Validation Loss: 1.4704
Epoch [154/400] Training Loss: 0.1640, Validation Loss: 1.4813
Epoch [155/400] Training Loss: 0.1578, Validation Loss: 1.7180
Epoch [156/400] Training Loss: 0.1227, Validation Loss: 1.5392
Epoch [157/400] Training Loss: 0.1360, Validation Loss: 1.6272
Epoch [158/400] Training Loss: 0.1454, Validation Loss: 1.5739
Epoch [159/400] Training Loss: 0.1445, Validation Loss: 1.6100
Epoch [160/400] Training Loss: 0.1521, Validation Loss: 1.7577
Epoch [161/400] Training Loss: 0.1695, Validation Loss: 1.5051
Epoch [162/400] Training Loss: 0.1428, Validation Loss: 1.5931
Epoch [163/400] Training Loss: 0.1360, Validation Loss: 1.5064
Epoch [164/400] Training Loss: 0.1195, Validation Loss: 1.5373
Epoch [165/400] Training Loss: 0.1097, Validation Loss: 1.4637
Epoch [166/400] Training Loss: 0.1293, Validation Loss: 1.4751
Epoch [167/400] Training Loss: 0.1250, Validation Loss: 1.5178
Epoch [168/400] Training Loss: 0.1177, Validation Loss: 1.6022
Epoch [169/400] Training Loss: 0.1304, Validation Loss: 1.5911
Epoch [170/400] Training Loss: 0.1429, Validation Loss: 1.5140
Epoch [171/400] Training Loss: 0.1589, Validation Loss: 1.6232
Epoch [172/400] Training Loss: 0.1207, Validation Loss: 1.5336
Epoch [173/400] Training Loss: 0.1251, Validation Loss: 1.7338
Epoch [174/400] Training Loss: 0.1157, Validation Loss: 1.4833
Epoch [175/400] Training Loss: 0.1039, Validation Loss: 1.4332
