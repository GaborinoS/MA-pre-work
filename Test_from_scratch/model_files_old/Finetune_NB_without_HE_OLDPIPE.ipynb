{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADSMI\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import torchvision\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import torch\n",
    "import torchaudio.transforms as T\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim, nn\n",
    "\n",
    "#own modules\n",
    "import config\n",
    "from utils_dir.utils import *\n",
    "\n",
    "#empty cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "###############Dataloader for training the model####################\n",
    "if config.ADSMI:\n",
    "    from DL_finetune import ADSMI_DL_finetune as DSf\n",
    "    Data_name = 'ADSMI'\n",
    "    print('ADSMI')\n",
    "if config.ESC_50:\n",
    "    from DL_finetune import ESC_50_DL_finetune as DSf\n",
    "    Data_name = 'ESC-50'\n",
    "    print('ESC-50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "# contrastive triplet model with resnet50 without dropout\n",
    "\n",
    "class ContrastiveTripletModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ContrastiveTripletModel, self).__init__()\n",
    "        self.resnet50 = models.resnet50(pretrained=True)\n",
    "        \n",
    "        # Modifications for your dataset:\n",
    "        # Assuming your data is a spectrogram of shape [128, X]. \n",
    "        # ResNet50 expects 3-channel inputs, so let's adapt the first layer.\n",
    "        self.resnet50.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        \n",
    "        # Remove last FC layer to get embeddings\n",
    "        self.encoder = nn.Sequential(*list(self.resnet50.children())[:-1])\n",
    "        \n",
    "        # Dropout layer (with 50% probability, adjust as needed)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward_one(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), -1) # Flatten for easier downstream processing\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, input1, input2, input3):\n",
    "        output1 = self.forward_one(input1)\n",
    "        output2 = self.forward_one(input2)\n",
    "        output3 = self.forward_one(input3)\n",
    "        return output1, output2, output3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveTripletModel(nn.Module):\n",
    "    def __init__(self, embedding_dim=2048, projection_dim=128,input_channels=config.channels):\n",
    "        super(ContrastiveTripletModel, self).__init__()\n",
    "        self.resnet50 = models.resnet50(pretrained=False)\n",
    "        \n",
    "        # Modifications for your dataset:\n",
    "        # Assuming your data is a spectrogram of shape [128, X]. \n",
    "        # ResNet50 expects 3-channel inputs, so let's adapt the first layer.\n",
    "        self.resnet50.conv1 = nn.Conv2d(input_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        \n",
    "        # Remove last FC layer to get embeddings\n",
    "        self.encoder = nn.Sequential(*list(self.resnet50.children())[:-1])\n",
    "        \n",
    "        # Projection head\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, embedding_dim),  # 1st projection layer, can be modified\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_dim, projection_dim)  # 2nd projection layer\n",
    "        )\n",
    "        \n",
    "        # Dropout layer (with 50% probability, adjust as needed)\n",
    "        #self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward_one(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten for easier downstream processing\n",
    "        x = self.projection(x)  # Pass through the projection head\n",
    "        #x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, input1, input2, input3):\n",
    "        output1 = self.forward_one(input1)\n",
    "        output2 = self.forward_one(input2)\n",
    "        output3 = self.forward_one(input3)\n",
    "        return output1, output2, output3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set here the Model that should be fintuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"./results/CLR-2035-10-17-Cluster_TRY1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineTuneModel(nn.Module):\n",
    "    def __init__(self, encoder, num_classes):\n",
    "        super(FineTuneModel, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        # Insert input size of the encoder here 2048\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = config.finetune_epochs\n",
    "learning_rate = config.lr\n",
    "weight_decay = 1e-5  # L2 regularization\n",
    "batch_size = 32\n",
    "\n",
    "# Device configuration\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 60  # This value can be changed based on how many epochs of no improvement you're willing to wait\n",
    "early_stop_counter = 0\n",
    "\n",
    "# Initialize dataset and dataloaders\n",
    "train_loader, test_loader = DSf.create_generators_finetune()\n",
    "\n",
    "# Load the entire pre-trained model (from your contrastive training)\n",
    "pretrained_model = torch.load(log_dir + '/checkpoint.pth')\n",
    "encoder_trained = pretrained_model.encoder\n",
    "\n",
    "# Initialize the FineTuneModel with the pre-trained encoder\n",
    "num_classes = 50  # Adjust this to the number of classes in your dataset\n",
    "model = FineTuneModel(encoder_trained, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Create log directory\n",
    "current_date = datetime.datetime.now().strftime('%Y-%m-%d-%H')\n",
    "log_dir = f\"./finetune_results/FineTune-{current_date}-epochs-{num_epochs}\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Log file path\n",
    "log_file_path = os.path.join(log_dir, \"training_log.txt\")\n",
    "\n",
    "# Variables for checkpointing\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for _, (file_name, data, labels) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    \n",
    "    # Validation loop (You may need to modify this to fit your specific use-case)\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for _, (file_name, data, labels) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "\n",
    "    # Save model if validation loss improves\n",
    "        # Check for early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        print(\"Validation Loss improved! Saving the model...\")\n",
    "        torch.save(model, log_dir + '/checkpoint.pth')\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "    \n",
    "    # Log to file\n",
    "    with open(log_file_path, 'a') as log_file:\n",
    "        log_file.write(f\"Epoch [{epoch+1}/{num_epochs}] Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/66 [00:41<44:37, 41.20s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Gabriel\\OneDrive\\Dokumente\\GitHub\\MA-pre-work\\Test_from_scratch\\Finetune_NB.ipynb Cell 8\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Finetune_NB.ipynb#X10sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Finetune_NB.ipynb#X10sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m train_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Finetune_NB.ipynb#X10sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m \u001b[39mfor\u001b[39;00m _, (file_name, data, labels) \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(train_loader), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(train_loader)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Finetune_NB.ipynb#X10sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Finetune_NB.ipynb#X10sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\tqdm\\std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1183\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\OneDrive\\Dokumente\\GitHub\\MA-pre-work\\Test_from_scratch\\DL_finetune\\ADSMI_DL_finetune.py:72\u001b[0m, in \u001b[0;36mMyDataset_finetune.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     70\u001b[0m file_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_names[index ]  \n\u001b[0;32m     71\u001b[0m path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot \u001b[39m+\u001b[39m file_name\n\u001b[1;32m---> 72\u001b[0m wave, rate \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39;49mload(path, sr\u001b[39m=\u001b[39;49m\u001b[39m44100\u001b[39;49m)\n\u001b[0;32m     74\u001b[0m \u001b[39m#identifying the label of the sample from its name\u001b[39;00m\n\u001b[0;32m     75\u001b[0m class_id \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_ids[index])\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\librosa\\util\\decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[0;32m     87\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     90\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     91\u001b[0m args_msg \u001b[39m=\u001b[39m [\n\u001b[0;32m     92\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[0;32m     93\u001b[0m     \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[39m-\u001b[39mextra_args:])\n\u001b[0;32m     94\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\librosa\\core\\audio.py:183\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    180\u001b[0m     y \u001b[39m=\u001b[39m to_mono(y)\n\u001b[0;32m    182\u001b[0m \u001b[39mif\u001b[39;00m sr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 183\u001b[0m     y \u001b[39m=\u001b[39m resample(y, orig_sr\u001b[39m=\u001b[39;49msr_native, target_sr\u001b[39m=\u001b[39;49msr, res_type\u001b[39m=\u001b[39;49mres_type)\n\u001b[0;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     sr \u001b[39m=\u001b[39m sr_native\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\librosa\\util\\decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[0;32m     87\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     90\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     91\u001b[0m args_msg \u001b[39m=\u001b[39m [\n\u001b[0;32m     92\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[0;32m     93\u001b[0m     \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[39m-\u001b[39mextra_args:])\n\u001b[0;32m     94\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\librosa\\core\\audio.py:617\u001b[0m, in \u001b[0;36mresample\u001b[1;34m(y, orig_sr, target_sr, res_type, fix, scale, **kwargs)\u001b[0m\n\u001b[0;32m    615\u001b[0m     y_hat \u001b[39m=\u001b[39m soxr\u001b[39m.\u001b[39mresample(y\u001b[39m.\u001b[39mT, orig_sr, target_sr, quality\u001b[39m=\u001b[39mres_type)\u001b[39m.\u001b[39mT\n\u001b[0;32m    616\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 617\u001b[0m     y_hat \u001b[39m=\u001b[39m resampy\u001b[39m.\u001b[39;49mresample(y, orig_sr, target_sr, \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49mres_type, axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    619\u001b[0m \u001b[39mif\u001b[39;00m fix:\n\u001b[0;32m    620\u001b[0m     y_hat \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mfix_length(y_hat, size\u001b[39m=\u001b[39mn_samples, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\resampy\\core.py:168\u001b[0m, in \u001b[0;36mresample\u001b[1;34m(x, sr_orig, sr_new, axis, filter, parallel, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m         resample_f_s(\n\u001b[0;32m    159\u001b[0m             x\u001b[39m.\u001b[39mswapaxes(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, axis),\n\u001b[0;32m    160\u001b[0m             t_out,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    165\u001b[0m             y\u001b[39m.\u001b[39mswapaxes(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, axis),\n\u001b[0;32m    166\u001b[0m         )\n\u001b[0;32m    167\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m     resample_f_s(\n\u001b[0;32m    169\u001b[0m         x\u001b[39m.\u001b[39;49mswapaxes(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, axis),\n\u001b[0;32m    170\u001b[0m         t_out,\n\u001b[0;32m    171\u001b[0m         interp_win,\n\u001b[0;32m    172\u001b[0m         interp_delta,\n\u001b[0;32m    173\u001b[0m         precision,\n\u001b[0;32m    174\u001b[0m         scale,\n\u001b[0;32m    175\u001b[0m         y\u001b[39m.\u001b[39;49mswapaxes(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, axis),\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    178\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\numba\\np\\ufunc\\gufunc.py:193\u001b[0m, in \u001b[0;36mGUFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd(sig)\n\u001b[0;32m    192\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_ufunc()\n\u001b[1;32m--> 193\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mufunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Hyperparameters\n",
    "num_epochs = config.finetune_epochs\n",
    "learning_rate = config.lr\n",
    "weight_decay = 1e-5  # L2 regularization\n",
    "batch_size = config.batch_size\n",
    "num_classes = config.class_numbers  # Adjust this to the number of classes in your dataset\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = config.patience  # This value can be changed based on how many epochs of no improvement you're willing to wait\n",
    "early_stop_counter = 0\n",
    "\n",
    "# Initialize dataset and dataloaders\n",
    "train_loader, test_loader = DSf.create_generators_finetune()\n",
    "\n",
    "# Load the entire pre-trained model (from your contrastive training)\n",
    "pretrained_model = torch.load(log_dir + '/checkpoint.pth')\n",
    "encoder_trained = pretrained_model.encoder\n",
    "\n",
    "# Initialize the FineTuneModel with the pre-trained encoder\n",
    "model = FineTuneModel(encoder_trained, num_classes).to(device)\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Assuming the WarmUpExponentialLR class and config values are available\n",
    "scheduler = WarmUpExponentialLR(optimizer, cold_epochs= 0, warm_epochs= config.warm_epochs, gamma=config.gamma)  # Adjust warm_epochs and gamma as needed\n",
    "\n",
    "\n",
    "# One-hot encoding and custom loss function\n",
    "def hotEncoder(v):\n",
    "    ret_vec = torch.zeros(v.shape[0], num_classes).to(device)\n",
    "    for s in range(v.shape[0]):\n",
    "        ret_vec[s][v[s]] = 1\n",
    "    return ret_vec\n",
    "\n",
    "def cross_entropy_one_hot(input, target):\n",
    "    _, labels = target.max(dim=1)\n",
    "    return nn.CrossEntropyLoss()(input, labels)\n",
    "\n",
    "# Create log directory\n",
    "current_date = datetime.datetime.now().strftime('%Y-%m-%d-%H')\n",
    "log_dir = f\"./finetune_results/FineTune-{current_date}-epochs-{num_epochs}-{Data_name}\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Log file path\n",
    "log_file_path = os.path.join(log_dir, \"training_log.txt\")\n",
    "\n",
    "#write in log file the hyperparameters\n",
    "with open(log_file_path, 'a') as log_file:\n",
    "    log_file.write(f\"##############################################################################\\n\")\n",
    "    log_file.write(f\"Hyperparameters:\\n\")\n",
    "    if config.ADSMI:\n",
    "        log_file.write(f\"ADSMI labeled Data\\n\")\n",
    "    if config.ESC_50:\n",
    "        log_file.write(f\"ESC-50 labeled Data\\n\")\n",
    "\n",
    "    log_file.write(f\"num_epochs: {num_epochs}\\n\")\n",
    "    log_file.write(f\"initial_learning_rate: {learning_rate}\\n\")\n",
    "    log_file.write(f\"weight_decay: {weight_decay}\\n\")\n",
    "    log_file.write(f\"batch_size: {batch_size}\\n\")\n",
    "    log_file.write(f\"patience: {patience}\\n\")\n",
    "    log_file.write(f\"early_stop_counter: {early_stop_counter}\\n\")\n",
    "    log_file.write(f\"num_classes: {num_classes}\\n\")\n",
    "    #log_file.write(f\"model: {model}\\n\")\n",
    "    log_file.write(f\"criterion: CrossEntropyLoss()\\n\")\n",
    "    #log_file.write(f\"optimizer: {optimizer}\\n\")\n",
    "    #log_file.write(f\"scheduler: {scheduler}\\n\")\n",
    "    #log_file.write(f\"log_dir: {log_dir}\\n\")\n",
    "    log_file.write(f\"log_file_path: {log_file_path}\\n\")\n",
    "    #log_file.write(f\"train_loader: {train_loader}\\n\")\n",
    "    #log_file.write(f\"test_loader: {test_loader}\\n\")\n",
    "    log_file.write(f\"##############################################################################\\n\")\n",
    "\n",
    "# Variables for checkpointing\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for _, (file_name, data, labels) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device).unsqueeze(1)\n",
    "        label_vec = hotEncoder(labels)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "        loss = cross_entropy_one_hot(outputs, label_vec)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for _, (file_name, data, labels) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device).unsqueeze(1)\n",
    "            label_vec = hotEncoder(labels)\n",
    "            outputs = model(data)\n",
    "            loss = cross_entropy_one_hot(outputs, label_vec)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "\n",
    "    # Check for early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        print(\"Validation Loss improved! Saving the model...\")\n",
    "\n",
    "        # Log to file\n",
    "        with open(log_file_path, 'a') as log_file:\n",
    "            log_file.write(f\"Validation Loss improved! Saving the model...\\n\")\n",
    "        \n",
    "        torch.save(model, log_dir + '/checkpoint.pth')\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "    \n",
    "    #scheduler step update the learning rate  \n",
    "    scheduler.step()         \n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "    # Log to file early stoping counter\n",
    "    with open(log_file_path, 'a') as log_file:\n",
    "        log_file.write(f\"Early stopping counter: {early_stop_counter} from {patience}\\n\")\n",
    "\n",
    "    # Log to file\n",
    "    with open(log_file_path, 'a') as log_file:\n",
    "        log_file.write(f\"Epoch [{epoch+1}/{num_epochs}] Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\\n\")\n",
    "        log_file.write(f\"##\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "# Initialize variables to store the true and predicted labels\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "with torch.no_grad():\n",
    "    for (file_name, data, labels) in tqdm(test_loader):\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(data)\n",
    "        \n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        pred_labels.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_preds = sum(t == p for t, p in zip(true_labels, pred_labels))\n",
    "accuracy = correct_preds / len(true_labels)\n",
    "\n",
    "# Calculate precision, recall, F1-score, and support\n",
    "precision, recall, f1_score, support = precision_recall_fscore_support(true_labels, pred_labels, average='weighted')\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_mat = confusion_matrix(true_labels, pred_labels)\n",
    "\n",
    "# Print the classification report\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1-score: {f1_score * 100:.2f}%\")\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:46<07:01, 46.87s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Gabriel\\OneDrive\\Dokumente\\GitHub\\MA-pre-work\\Test_from_scratch\\Finetune_NB.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Finetune_NB.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Evaluate the model on the test dataset\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Finetune_NB.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Finetune_NB.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mfor\u001b[39;00m (file_name, data, labels) \u001b[39min\u001b[39;00m tqdm(test_loader):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Finetune_NB.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gabriel/OneDrive/Dokumente/GitHub/MA-pre-work/Test_from_scratch/Finetune_NB.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\tqdm\\std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1183\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\OneDrive\\Dokumente\\GitHub\\MA-pre-work\\Test_from_scratch\\DL_finetune\\ADSMI_DL_finetune.py:72\u001b[0m, in \u001b[0;36mMyDataset_finetune.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     70\u001b[0m file_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_names[index ]  \n\u001b[0;32m     71\u001b[0m path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot \u001b[39m+\u001b[39m file_name\n\u001b[1;32m---> 72\u001b[0m wave, rate \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39;49mload(path, sr\u001b[39m=\u001b[39;49m\u001b[39m44100\u001b[39;49m)\n\u001b[0;32m     74\u001b[0m \u001b[39m#identifying the label of the sample from its name\u001b[39;00m\n\u001b[0;32m     75\u001b[0m class_id \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_ids[index])\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\librosa\\util\\decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[0;32m     87\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     90\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     91\u001b[0m args_msg \u001b[39m=\u001b[39m [\n\u001b[0;32m     92\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[0;32m     93\u001b[0m     \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[39m-\u001b[39mextra_args:])\n\u001b[0;32m     94\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\librosa\\core\\audio.py:183\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    180\u001b[0m     y \u001b[39m=\u001b[39m to_mono(y)\n\u001b[0;32m    182\u001b[0m \u001b[39mif\u001b[39;00m sr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 183\u001b[0m     y \u001b[39m=\u001b[39m resample(y, orig_sr\u001b[39m=\u001b[39;49msr_native, target_sr\u001b[39m=\u001b[39;49msr, res_type\u001b[39m=\u001b[39;49mres_type)\n\u001b[0;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     sr \u001b[39m=\u001b[39m sr_native\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\librosa\\util\\decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[0;32m     87\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     90\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     91\u001b[0m args_msg \u001b[39m=\u001b[39m [\n\u001b[0;32m     92\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[0;32m     93\u001b[0m     \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[39m-\u001b[39mextra_args:])\n\u001b[0;32m     94\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\librosa\\core\\audio.py:617\u001b[0m, in \u001b[0;36mresample\u001b[1;34m(y, orig_sr, target_sr, res_type, fix, scale, **kwargs)\u001b[0m\n\u001b[0;32m    615\u001b[0m     y_hat \u001b[39m=\u001b[39m soxr\u001b[39m.\u001b[39mresample(y\u001b[39m.\u001b[39mT, orig_sr, target_sr, quality\u001b[39m=\u001b[39mres_type)\u001b[39m.\u001b[39mT\n\u001b[0;32m    616\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 617\u001b[0m     y_hat \u001b[39m=\u001b[39m resampy\u001b[39m.\u001b[39;49mresample(y, orig_sr, target_sr, \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49mres_type, axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    619\u001b[0m \u001b[39mif\u001b[39;00m fix:\n\u001b[0;32m    620\u001b[0m     y_hat \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mfix_length(y_hat, size\u001b[39m=\u001b[39mn_samples, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\resampy\\core.py:168\u001b[0m, in \u001b[0;36mresample\u001b[1;34m(x, sr_orig, sr_new, axis, filter, parallel, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m         resample_f_s(\n\u001b[0;32m    159\u001b[0m             x\u001b[39m.\u001b[39mswapaxes(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, axis),\n\u001b[0;32m    160\u001b[0m             t_out,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    165\u001b[0m             y\u001b[39m.\u001b[39mswapaxes(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, axis),\n\u001b[0;32m    166\u001b[0m         )\n\u001b[0;32m    167\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m     resample_f_s(\n\u001b[0;32m    169\u001b[0m         x\u001b[39m.\u001b[39;49mswapaxes(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, axis),\n\u001b[0;32m    170\u001b[0m         t_out,\n\u001b[0;32m    171\u001b[0m         interp_win,\n\u001b[0;32m    172\u001b[0m         interp_delta,\n\u001b[0;32m    173\u001b[0m         precision,\n\u001b[0;32m    174\u001b[0m         scale,\n\u001b[0;32m    175\u001b[0m         y\u001b[39m.\u001b[39;49mswapaxes(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, axis),\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    178\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\numba\\np\\ufunc\\gufunc.py:193\u001b[0m, in \u001b[0;36mGUFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd(sig)\n\u001b[0;32m    192\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_ufunc()\n\u001b[1;32m--> 193\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mufunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "# Initialize variables to store the true and predicted labels\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model = torch.load('finetune_results/test/checkpoint.pth')\n",
    "model.eval()\n",
    "\n",
    "# Initialize dataset and dataloaders\n",
    "train_loader, test_loader = DSf.create_generators_finetune()\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "with torch.no_grad():\n",
    "    for (file_name, data, labels) in tqdm(test_loader):\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(data)\n",
    "        \n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        pred_labels.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "\n",
    "# Convert lists to arrays for better indexing and operations\n",
    "true_labels = np.array(true_labels)\n",
    "pred_labels = np.array(pred_labels)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_preds = np.sum(true_labels == pred_labels)\n",
    "accuracy = correct_preds / len(true_labels)\n",
    "\n",
    "# Calculate precision, recall, F1-score, and support\n",
    "precision, recall, f1_score, support = precision_recall_fscore_support(true_labels, pred_labels, average='weighted')\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_mat = confusion_matrix(true_labels, pred_labels)\n",
    "\n",
    "# Print the classification report\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1-score: {f1_score * 100:.2f}%\")\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
