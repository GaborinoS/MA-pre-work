Epoch [1/400] Training Loss: 3.7365, Validation Loss: 4.1258
Epoch [2/400] Training Loss: 3.1010, Validation Loss: 3.2812
Epoch [3/400] Training Loss: 2.8176, Validation Loss: 3.7458
Epoch [4/400] Training Loss: 2.5067, Validation Loss: 2.4488
Epoch [5/400] Training Loss: 2.2943, Validation Loss: 2.3960
Epoch [6/400] Training Loss: 2.0682, Validation Loss: 2.3391
Epoch [7/400] Training Loss: 1.8672, Validation Loss: 2.7581
Epoch [8/400] Training Loss: 1.7441, Validation Loss: 1.9852
Epoch [9/400] Training Loss: 1.5699, Validation Loss: 1.7404
Epoch [10/400] Training Loss: 1.4889, Validation Loss: 7.9080
Epoch [11/400] Training Loss: 1.3988, Validation Loss: 4.0100
Epoch [12/400] Training Loss: 1.2920, Validation Loss: 1.9115
Epoch [13/400] Training Loss: 1.1934, Validation Loss: 4.1438
Epoch [14/400] Training Loss: 1.1575, Validation Loss: 2.7720
Epoch [15/400] Training Loss: 1.1079, Validation Loss: 3.2186
Epoch [16/400] Training Loss: 0.9951, Validation Loss: 2.1603
Epoch [17/400] Training Loss: 1.0122, Validation Loss: 2.7968
Epoch [18/400] Training Loss: 0.9190, Validation Loss: 1.8662
Epoch [19/400] Training Loss: 0.8610, Validation Loss: 1.8774
Epoch [20/400] Training Loss: 0.8891, Validation Loss: 2.4818
Epoch [21/400] Training Loss: 0.7711, Validation Loss: 1.9117
Epoch [22/400] Training Loss: 0.7282, Validation Loss: 1.4022
Epoch [23/400] Training Loss: 0.7670, Validation Loss: 2.6847
Epoch [24/400] Training Loss: 0.7170, Validation Loss: 1.5150
Epoch [25/400] Training Loss: 0.6485, Validation Loss: 3.0967
Epoch [26/400] Training Loss: 0.6009, Validation Loss: 3.1395
Epoch [27/400] Training Loss: 0.6365, Validation Loss: 1.8836
Epoch [28/400] Training Loss: 0.5643, Validation Loss: 4.7128
Epoch [29/400] Training Loss: 0.5832, Validation Loss: 2.8293
Epoch [30/400] Training Loss: 0.5585, Validation Loss: 1.9416
Epoch [31/400] Training Loss: 0.5610, Validation Loss: 14.4098
Epoch [32/400] Training Loss: 0.4993, Validation Loss: 3.1973
Epoch [33/400] Training Loss: 0.4882, Validation Loss: 3.0552
Epoch [34/400] Training Loss: 0.4939, Validation Loss: 1.6117
Epoch [35/400] Training Loss: 0.5170, Validation Loss: 1.6944
Epoch [36/400] Training Loss: 0.4183, Validation Loss: 1.3260
Epoch [37/400] Training Loss: 0.4043, Validation Loss: 3.6283
Epoch [38/400] Training Loss: 0.4572, Validation Loss: 1.2484
Epoch [39/400] Training Loss: 0.3992, Validation Loss: 1.3650
Epoch [40/400] Training Loss: 0.3989, Validation Loss: 2.1647
Epoch [41/400] Training Loss: 0.3459, Validation Loss: 1.3499
Epoch [42/400] Training Loss: 0.4066, Validation Loss: 1.4222
Epoch [43/400] Training Loss: 0.4216, Validation Loss: 2.5902
Epoch [44/400] Training Loss: 0.3656, Validation Loss: 1.4589
Epoch [45/400] Training Loss: 0.3812, Validation Loss: 6.0230
Epoch [46/400] Training Loss: 0.3682, Validation Loss: 2.5887
Epoch [47/400] Training Loss: 0.3628, Validation Loss: 2.2940
Epoch [48/400] Training Loss: 0.3267, Validation Loss: 3.9221
Epoch [49/400] Training Loss: 0.3067, Validation Loss: 2.1591
Epoch [50/400] Training Loss: 0.2936, Validation Loss: 1.8927
Epoch [51/400] Training Loss: 0.3021, Validation Loss: 1.1345
Epoch [52/400] Training Loss: 0.2770, Validation Loss: 1.5259
Epoch [53/400] Training Loss: 0.3210, Validation Loss: 3.8112
Epoch [54/400] Training Loss: 0.3448, Validation Loss: 1.5770
Epoch [55/400] Training Loss: 0.3346, Validation Loss: 4.1949
Epoch [56/400] Training Loss: 0.2101, Validation Loss: 1.7397
Epoch [57/400] Training Loss: 0.2596, Validation Loss: 4.3703
Epoch [58/400] Training Loss: 0.2849, Validation Loss: 2.0516
Epoch [59/400] Training Loss: 0.2685, Validation Loss: 1.6696
Epoch [60/400] Training Loss: 0.2650, Validation Loss: 3.4501
Epoch [61/400] Training Loss: 0.2533, Validation Loss: 1.2177
Epoch [62/400] Training Loss: 0.2977, Validation Loss: 2.7006
Epoch [63/400] Training Loss: 0.3255, Validation Loss: 4.2954
Epoch [64/400] Training Loss: 0.2899, Validation Loss: 2.0937
Epoch [65/400] Training Loss: 0.2741, Validation Loss: 2.7389
Epoch [66/400] Training Loss: 0.2522, Validation Loss: 1.5666
Epoch [67/400] Training Loss: 0.2593, Validation Loss: 4.6022
Epoch [68/400] Training Loss: 0.1873, Validation Loss: 1.0771
Epoch [69/400] Training Loss: 0.1728, Validation Loss: 1.9008
Epoch [70/400] Training Loss: 0.2531, Validation Loss: 4.0970
Epoch [71/400] Training Loss: 0.2312, Validation Loss: 4.8183
Epoch [72/400] Training Loss: 0.2386, Validation Loss: 1.3322
Epoch [73/400] Training Loss: 0.2369, Validation Loss: 1.3744
Epoch [74/400] Training Loss: 0.2410, Validation Loss: 1.3978
Epoch [75/400] Training Loss: 0.1557, Validation Loss: 1.6368
Epoch [76/400] Training Loss: 0.1535, Validation Loss: 1.9693
Epoch [77/400] Training Loss: 0.2306, Validation Loss: 1.3504
Epoch [78/400] Training Loss: 0.2117, Validation Loss: 2.8239
Epoch [79/400] Training Loss: 0.1911, Validation Loss: 1.4353
Epoch [80/400] Training Loss: 0.1889, Validation Loss: 3.3203
Epoch [81/400] Training Loss: 0.2311, Validation Loss: 1.6473
Epoch [82/400] Training Loss: 0.2111, Validation Loss: 1.3170
Epoch [83/400] Training Loss: 0.1876, Validation Loss: 1.4676
Epoch [84/400] Training Loss: 0.1865, Validation Loss: 1.2494
Epoch [85/400] Training Loss: 0.1771, Validation Loss: 2.2270
Epoch [86/400] Training Loss: 0.1668, Validation Loss: 1.3332
Epoch [87/400] Training Loss: 0.1658, Validation Loss: 2.2431
Epoch [88/400] Training Loss: 0.1936, Validation Loss: 3.9585
Epoch [89/400] Training Loss: 0.1652, Validation Loss: 1.6741
Epoch [90/400] Training Loss: 0.2191, Validation Loss: 2.1837
Epoch [91/400] Training Loss: 0.2138, Validation Loss: 1.6791
Epoch [92/400] Training Loss: 0.1913, Validation Loss: 1.7123
Epoch [93/400] Training Loss: 0.1551, Validation Loss: 3.1859
Epoch [94/400] Training Loss: 0.1082, Validation Loss: 1.2446
Epoch [95/400] Training Loss: 0.1692, Validation Loss: 1.3093
Epoch [96/400] Training Loss: 0.1921, Validation Loss: 1.4469
Epoch [97/400] Training Loss: 0.1997, Validation Loss: 4.0508
Epoch [98/400] Training Loss: 0.1370, Validation Loss: 1.2180
Epoch [99/400] Training Loss: 0.1130, Validation Loss: 1.3824
Epoch [100/400] Training Loss: 0.1436, Validation Loss: 1.6245
Epoch [101/400] Training Loss: 0.1429, Validation Loss: 1.4002
Epoch [102/400] Training Loss: 0.1284, Validation Loss: 1.8044
Epoch [103/400] Training Loss: 0.2258, Validation Loss: 3.9370
Epoch [104/400] Training Loss: 0.1521, Validation Loss: 1.3775
Epoch [105/400] Training Loss: 0.1529, Validation Loss: 1.8525
Epoch [106/400] Training Loss: 0.1419, Validation Loss: 1.3604
Epoch [107/400] Training Loss: 0.1922, Validation Loss: 9.1923
Epoch [108/400] Training Loss: 0.1308, Validation Loss: 3.0020
Epoch [109/400] Training Loss: 0.1264, Validation Loss: 2.4691
Epoch [110/400] Training Loss: 0.1410, Validation Loss: 1.2785
Epoch [111/400] Training Loss: 0.1393, Validation Loss: 1.9066
Epoch [112/400] Training Loss: 0.1634, Validation Loss: 1.3726
Epoch [113/400] Training Loss: 0.1496, Validation Loss: 1.6060
Epoch [114/400] Training Loss: 0.1543, Validation Loss: 1.2488
Epoch [115/400] Training Loss: 0.1212, Validation Loss: 7.5496
Epoch [116/400] Training Loss: 0.1298, Validation Loss: 1.5045
Epoch [117/400] Training Loss: 0.1393, Validation Loss: 7.7099
Epoch [118/400] Training Loss: 0.1297, Validation Loss: 1.5852
Epoch [119/400] Training Loss: 0.1247, Validation Loss: 2.5285
Epoch [120/400] Training Loss: 0.1662, Validation Loss: 4.3850
Epoch [121/400] Training Loss: 0.1270, Validation Loss: 1.3290
Epoch [122/400] Training Loss: 0.1352, Validation Loss: 2.5799
Epoch [123/400] Training Loss: 0.1253, Validation Loss: 4.2123
Epoch [124/400] Training Loss: 0.1056, Validation Loss: 1.4053
Epoch [125/400] Training Loss: 0.1395, Validation Loss: 2.0440
Epoch [126/400] Training Loss: 0.1766, Validation Loss: 2.3947
Epoch [127/400] Training Loss: 0.1303, Validation Loss: 2.5331
